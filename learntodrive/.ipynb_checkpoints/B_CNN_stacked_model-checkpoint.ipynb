{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from learntodrive.models.CNN_Model_Stacked import densenet121\n",
    "from learntodrive.dataloader_aug_seq import Drive360Loader\n",
    "\n",
    "from learntodrive.utils import move_target_to_cuda\n",
    "from learntodrive.utils import move_data_to_cuda\n",
    "from learntodrive.utils import log_textfile\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_validation(model, validation_loader):\n",
    "  model.eval()\n",
    "  target_speed = np.array([])\n",
    "  target_steer = np.array([])\n",
    "  pred_speed = np.array([])\n",
    "  pred_steer = np.array([])\n",
    "  with torch.no_grad():\n",
    "      for batch_idx, (data, target, front_name) in enumerate(validation_loader):\n",
    "          data = move_data_to_cuda(data)\n",
    "          target = move_target_to_cuda(target)\n",
    "          #resnet34_features = get_features(front_name, resnet34).cuda()\n",
    "          prediction = model(data, [])\n",
    "          # Again only evaluating the canSpeed \n",
    "          # predictions, add canSteering when \n",
    "          # jointly training.\n",
    "          cur_pred_speed = np.asarray(prediction['canSpeed'].detach().cpu())\n",
    "          cur_pred_steer = np.asarray(prediction['canSteering'].detach().cpu())\n",
    "          cur_target_speed = np.asarray(target['canSpeed'].detach().cpu())\n",
    "          cur_target_steer = np.asarray(target['canSteering'].detach().cpu())\n",
    "          cur_pred_steer = (cur_pred_steer*target_std['canSteering'])+target_mean['canSteering']\n",
    "          cur_target_steer = (cur_target_steer*target_std['canSteering'])+target_mean['canSteering']\n",
    "          cur_pred_speed = (cur_pred_speed*target_std['canSpeed'])+target_mean['canSpeed']\n",
    "          cur_target_speed = (cur_target_speed*target_std['canSpeed'])+target_mean['canSpeed']\n",
    "          pred_speed = np.concatenate([pred_speed, cur_pred_speed])\n",
    "          pred_steer = np.concatenate([pred_steer, cur_pred_steer])\n",
    "          target_speed = np.concatenate([target_speed, cur_target_speed])\n",
    "          target_steer = np.concatenate([target_steer, cur_target_steer])\n",
    "\n",
    "          if (batch_idx+1) % 10 == 0:\n",
    "                  print(\"Validation batch: \" + str(batch_idx+1))\n",
    "  mse_steer = (np.square(pred_steer - target_steer)).mean()\n",
    "  mse_speed = (np.square(pred_speed - target_speed)).mean()\n",
    "  return(mse_steer, mse_speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 0.035043,
     "end_time": "2019-10-20T05:17:53.440555",
     "exception": false,
     "start_time": "2019-10-20T05:17:53.405512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "road_idx = {\n",
    "    6: 1, #ground\n",
    "    7: 2, #road\n",
    "    8: 3, #sidewalk\n",
    "    9: 4, #parking\n",
    "    10: 5,#railroad\n",
    "    11: 6,#building\n",
    "    12: 6,#wall\n",
    "    13: 6,#fence\n",
    "    23: 7,#sky\n",
    "    24: 8,#person\n",
    "    25: 9,#rider\n",
    "    26: 10,#car\n",
    "    27: 10,#truck\n",
    "    28: 10,#bus\n",
    "    29: 10,#caravan\n",
    "    30: 10,#trailer\n",
    "    31: 11,#train\n",
    "    32: 12,#mortocyle\n",
    "    33: 13 #bycicle   \n",
    "}\n",
    "\n",
    "epochs = 100\n",
    "logfile = './logs/CNN_stacked.log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ztA2jxchjizf",
    "papermill": {
     "duration": 0.052604,
     "end_time": "2019-10-20T05:17:53.591110",
     "exception": false,
     "start_time": "2019-10-20T05:17:53.538506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "\n",
    "config = json.load(open('config_sample1.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BiQeSNuDjjW2",
    "papermill": {
     "duration": 0.03375,
     "end_time": "2019-10-20T05:17:53.709716",
     "exception": false,
     "start_time": "2019-10-20T05:17:53.675966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config['data_loader']['historic']['number'] = 10\n",
    "config['data_loader']['train']['batch_size'] = 13\n",
    "config['data_loader']['validation']['batch_size'] = 13\n",
    "config['data_loader']['test']['batch_size'] = 13\n",
    "\n",
    "target_mean = config['target']['mean']\n",
    "target_std = config['target']['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "tjDjbB77jlFO",
    "outputId": "206367d4-a58d-4676-e12d-e5d7af986bcb",
    "papermill": {
     "duration": 2.461655,
     "end_time": "2019-10-20T05:17:56.197041",
     "exception": false,
     "start_time": "2019-10-20T05:17:53.735386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase: train # of data: 65245\n",
      "Phase: validation # of data: 10266\n",
      "Phase: test # of data: 27920\n",
      "Loaded train loader with the following data available as a dict.\n",
      "Index(['cameraRight', 'cameraFront', 'cameraRear', 'cameraLeft', 'canSteering',\n",
      "       'canSpeed', 'chapter'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# create a train, validation and test data loader\n",
    "train_loader = Drive360Loader(config, 'train', 0.8, road_idx)\n",
    "validation_loader = Drive360Loader(config, 'validation', 0, road_idx)\n",
    "test_loader = Drive360Loader(config, 'test', 0, road_idx)\n",
    "\n",
    "# print the data (keys) available for use. See full \n",
    "# description of each data type in the documents.\n",
    "print('Loaded train loader with the following data available as a dict.')\n",
    "print(train_loader.drive360.dataframe.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "papermill": {
     "duration": 35.874402,
     "end_time": "2019-10-20T05:18:32.384477",
     "exception": false,
     "start_time": "2019-10-20T05:17:56.510075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = densenet121().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "k_Pdj33i6OoL",
    "outputId": "9bc753ab-ae87-46c7-a023-de811df4f7b8",
    "papermill": {
     "duration": 26099.239721,
     "end_time": "2019-10-20T12:33:31.902352",
     "exception": false,
     "start_time": "2019-10-20T05:18:32.662631",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "[epoch: 1, batch:    100] loss: 1.54802 time load: 0.10083 time model: 0.33089\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6ff1b3da1f4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mpred_speed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mpred_steer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfront_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmove_data_to_cuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmove_target_to_cuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    282\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m'''Get the fd.  This should only be called once.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_resource_sharer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/multiprocessing/reduction.py\u001b[0m in \u001b[0;36mrecv_handle\u001b[0;34m(conn)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;34m'''Receive a handle over a local connection.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAF_UNIX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mrecvfds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mDupFd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/multiprocessing/reduction.py\u001b[0m in \u001b[0;36mrecvfds\u001b[0;34m(sock, size)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mbytes_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mancdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maddr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecvmsg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCMSG_SPACE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mancdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0003)\n",
    "lr_decay_idx = 0\n",
    "lrates = [0.0001, 0.00005, 0.00003, 0.0001]\n",
    "lowestSpeedLoss = 999999\n",
    "lowestSteerLoss = 999999\n",
    "log_textfile(logfile, 'start')\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0\n",
    "    running_loss = 0.0\n",
    "    end = time.time()\n",
    "    model.train()\n",
    "    target_speed = np.array([])\n",
    "    target_steer = np.array([])\n",
    "    pred_speed = np.array([])\n",
    "    pred_steer = np.array([])\n",
    "    for batch_idx, (data, target, front_name) in enumerate(train_loader):\n",
    "        data = move_data_to_cuda(data)\n",
    "        target = move_target_to_cuda(target)\n",
    "        #resnet34_features = get_features(front_name, resnet34).cuda()\n",
    "        start = time.time()\n",
    "        delta_load = start-end\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(data, [])\n",
    "  \n",
    "        # Ony optimizing for canSpeed at the moment\n",
    "        # add canSteering to optimize simulatenously.\n",
    "        loss_speed = criterion(prediction['canSpeed'], target['canSpeed'])\n",
    "        loss_steering = criterion(prediction['canSteering'], target['canSteering'])\n",
    "        loss = loss_steering+loss_speed\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        cur_pred_speed = np.asarray(prediction['canSpeed'].detach().cpu())\n",
    "        cur_pred_steer = np.asarray(prediction['canSteering'].detach().cpu())\n",
    "        cur_target_speed = np.asarray(target['canSpeed'].detach().cpu())\n",
    "        cur_target_steer = np.asarray(target['canSteering'].detach().cpu())\n",
    "        cur_pred_steer = (cur_pred_steer*target_std['canSteering'])+target_mean['canSteering']\n",
    "        cur_target_steer = (cur_target_steer*target_std['canSteering'])+target_mean['canSteering']\n",
    "        cur_pred_speed = (cur_pred_speed*target_std['canSpeed'])+target_mean['canSpeed']\n",
    "        cur_target_speed = (cur_target_speed*target_std['canSpeed'])+target_mean['canSpeed']\n",
    "        pred_speed = np.concatenate([pred_speed, cur_pred_speed])\n",
    "        pred_steer = np.concatenate([pred_steer, cur_pred_steer])\n",
    "        target_speed = np.concatenate([target_speed, cur_target_speed])\n",
    "        target_steer = np.concatenate([target_steer, cur_target_steer])\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        total_loss += loss.item()\n",
    "        end = time.time()\n",
    "        delta_model = end - start\n",
    "        if (batch_idx+1) % 100 == 0:  \n",
    "            log_textfile(logfile, '[epoch: %d, batch:  %5d] loss: %.5f time load: %.5f time model: %.5f' % (epoch + 1, batch_idx + 1, running_loss / 100.0, delta_load, delta_model))\n",
    "            running_loss = 0.0\n",
    "    if epoch in [5, 15, 20, 200]:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group[\"lr\"] = lrates[lr_decay_idx]\n",
    "        print('LR:' + str(lrates[lr_decay_idx]))\n",
    "        lr_decay_idx += 1\n",
    "        \n",
    "        \n",
    "    shuffle(train_loader.drive360.indices)\n",
    "    mse_steer, mse_speed = run_validation(model, validation_loader)\n",
    "    mse_steer_t = (np.square(pred_steer - target_steer)).mean()\n",
    "    mse_speed_t = (np.square(pred_speed - target_speed)).mean()\n",
    "    torch.save(model, './models/CNN_stacked_last.pth')\n",
    "    if mse_steer < lowestSteerLoss:\n",
    "        torch.save(model, './models/CNN_stacked_beststeer.pth')\n",
    "        lowestSteerLoss = mse_steer\n",
    "    if mse_speed < lowestSpeedLoss:\n",
    "        torch.save(model, './models/CNN_stacked_bestspeed.pth')\n",
    "        lowestSpeedLoss = mse_speed\n",
    "    log_textfile(logfile, \"Epoch: \" + str(epoch + 1) + \"/\" + str(epochs) + \" Loss: \" + str(total_loss/batch_idx) + \" Train MSESteer: \" + str(round(mse_steer_t,3)) + \" Train MSESpeed: \" + str(round(mse_speed_t,3)) + \" MSESteer: \" + str(round(mse_steer,3)) + \" MSESpeed: \" + str(round(mse_speed,3)))\n",
    "\n",
    "print('Best Steer Loss:', lowestSteerLoss)\n",
    "print('Best Speed Loss:', lowestSpeedLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VY8FhOybc5Jr",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read in model\n",
    "modelSteer = torch.load('./models/CNN_stacked_beststeer.pth')\n",
    "modelSpeed = torch.load('./models/CNN_stacked_bestspeed.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OLgOpzrAE0OS",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalize_targets = config['target']['normalize']\n",
    "target_mean = config['target']['mean']\n",
    "target_std = config['target']['std']\n",
    "\n",
    "def add_results(results, predictionSteer, predictionSpeed, front_name):\n",
    "    steering = np.squeeze(predictionSteer['canSteering'].cpu().data.numpy())\n",
    "    speed = np.squeeze(predictionSpeed['canSpeed'].cpu().data.numpy())\n",
    "    last_image_names = front_name[0]\n",
    "    front_name = [x for x in last_image_names]\n",
    "    image_front_name = np.squeeze(np.array(front_name))\n",
    "    if normalize_targets:\n",
    "        steering = (steering*target_std['canSteering'])+target_mean['canSteering']\n",
    "        speed = (speed*target_std['canSpeed'])+target_mean['canSpeed']\n",
    "        front_name = front_name\n",
    "    if np.isscalar(steering):\n",
    "        steering = [steering]\n",
    "    if np.isscalar(speed):\n",
    "        speed = [speed]\n",
    "    results['canSteering'].extend(steering)\n",
    "    results['canSpeed'].extend(speed)\n",
    "    results['cameraFront'].extend(front_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Xlyl_ErE567",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'modelSteer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-1c94bcfc3da3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m            'cameraFront': []}\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodelSteer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmodelSpeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'modelSteer' is not defined"
     ]
    }
   ],
   "source": [
    "results = {'canSteering': [],\n",
    "           'canSpeed': [], \n",
    "           'cameraFront': []}\n",
    "\n",
    "modelSteer.eval()\n",
    "modelSpeed.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target, front_name) in enumerate(validation_loader):\n",
    "        data = move_data_to_cuda(data)\n",
    "        target = move_target_to_cuda(target)\n",
    "        predictionSteer = modelSteer(data, [])\n",
    "        predictionSpeed = modelSpeed(data, [])\n",
    "        add_results(results, predictionSteer, predictionSpeed, front_name)\n",
    "        \n",
    "df = pd.DataFrame.from_dict(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0rVxA9R4w_f9",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Read in full test data set and merge predictions and interpolate missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yQmCK4w8VM9y",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_full = pd.read_csv('./Data/test_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zq8-9yJJf10k",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# merge the predictions and the original test set\n",
    "complete_test_set = pd.merge(test_full, df, how='left', on='cameraFront')\n",
    "\n",
    "index_list = complete_test_set.groupby('chapter').apply(lambda x: x.iloc[100:]).index.droplevel(level=0).tolist()\n",
    "complete_test_set = complete_test_set.loc[index_list,]\n",
    "\n",
    "complete_test_set = complete_test_set.groupby('chapter').apply(lambda group: group.interpolate(method='linear'))\n",
    "complete_test_set['canSpeed'] = complete_test_set.groupby(['chapter'])['canSpeed'].bfill()\n",
    "complete_test_set['canSteering'] = complete_test_set.groupby(['chapter'])['canSteering'].bfill()\n",
    "\n",
    "if np.sum(np.sum(complete_test_set.isna())>0)>0:\n",
    "    print('Error some NA values!')\n",
    "    complete_test_set.to_csv('./submissions/error_submission.csv', index=False)\n",
    "else:\n",
    "    if complete_test_set.shape[0] != 279863 and False:\n",
    "        print('Sumbission file has wrong number of lines')\n",
    "    else:\n",
    "        print('Submission file has no NAs!')\n",
    "        submission_cols = complete_test_set[['canSteering', 'canSpeed']]\n",
    "        submission_cols.to_csv('./submissions/CNN_stacked_submission.csv', index=False) "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Model Simple 2 Sample3_subset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "papermill": {
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "NVIDIA_aug_correctaug_cont.ipynb",
   "output_path": "NVIDIA_aug_correctaug_cont_out.ipynb",
   "parameters": {},
   "start_time": "2019-10-20T05:17:27.015024",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
