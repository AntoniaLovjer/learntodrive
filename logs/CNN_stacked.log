[epoch: 1, batch:    200] loss: 1.42060 time load: 0.06917 time model: 0.32472
[epoch: 1, batch:    300] loss: 1.29449 time load: 0.06965 time model: 0.32387
[epoch: 1, batch:    400] loss: 1.21770 time load: 0.06595 time model: 0.32091
[epoch: 1, batch:    500] loss: 1.24757 time load: 0.07181 time model: 0.32298
[epoch: 1, batch:    600] loss: 1.29158 time load: 0.06742 time model: 0.32031
[epoch: 1, batch:    700] loss: 1.31315 time load: 0.06625 time model: 0.32557
[epoch: 1, batch:    800] loss: 1.40909 time load: 0.06801 time model: 0.32084
[epoch: 1, batch:    900] loss: 1.04835 time load: 0.08292 time model: 0.33182
[epoch: 1, batch:   1000] loss: 1.36908 time load: 0.06002 time model: 0.32582
[epoch: 1, batch:   1100] loss: 1.24932 time load: 0.06592 time model: 0.31768
[epoch: 1, batch:   1200] loss: 1.19607 time load: 0.07082 time model: 0.32672
[epoch: 1, batch:   1300] loss: 1.33050 time load: 0.06904 time model: 0.31716
[epoch: 1, batch:   1400] loss: 1.08898 time load: 0.07041 time model: 0.32466
[epoch: 1, batch:   1500] loss: 1.27456 time load: 0.06113 time model: 0.32134
[epoch: 1, batch:   1600] loss: 1.19080 time load: 0.06649 time model: 0.32239
[epoch: 1, batch:   1700] loss: 1.32364 time load: 0.07152 time model: 0.32218
[epoch: 1, batch:   1800] loss: 1.17872 time load: 0.07653 time model: 0.31769
[epoch: 1, batch:   1900] loss: 1.28310 time load: 0.05802 time model: 0.32028
[epoch: 1, batch:   2000] loss: 1.15513 time load: 0.07089 time model: 0.32189
[epoch: 1, batch:   2100] loss: 1.25383 time load: 0.06524 time model: 0.33491
[epoch: 1, batch:   2200] loss: 1.21295 time load: 0.07187 time model: 0.32364
[epoch: 1, batch:   2300] loss: 1.08764 time load: 0.06464 time model: 0.31897
[epoch: 1, batch:   2400] loss: 1.15004 time load: 0.06603 time model: 0.32844
[epoch: 1, batch:   2500] loss: 1.18445 time load: 0.06956 time model: 0.32532
[epoch: 1, batch:   2600] loss: 1.18763 time load: 0.06939 time model: 0.32405
[epoch: 1, batch:   2700] loss: 1.07771 time load: 0.06843 time model: 0.31829
[epoch: 1, batch:   2800] loss: 1.02609 time load: 0.06805 time model: 0.32380
[epoch: 1, batch:   2900] loss: 1.04497 time load: 0.07117 time model: 0.32212
[epoch: 1, batch:   3000] loss: 1.20433 time load: 0.06927 time model: 0.32280
[epoch: 1, batch:   3100] loss: 1.02099 time load: 0.06640 time model: 0.32296
[epoch: 1, batch:   3200] loss: 1.06053 time load: 0.06704 time model: 0.32381
[epoch: 1, batch:   3300] loss: 1.18763 time load: 0.06984 time model: 0.32120
[epoch: 1, batch:   3400] loss: 0.88505 time load: 0.06667 time model: 0.31901
[epoch: 1, batch:   3500] loss: 1.11493 time load: 0.06735 time model: 0.32123
[epoch: 1, batch:   3600] loss: 1.00925 time load: 0.07467 time model: 0.32407
[epoch: 1, batch:   3700] loss: 1.29811 time load: 0.07038 time model: 0.31909
[epoch: 1, batch:   3800] loss: 1.01224 time load: 0.06644 time model: 0.31858
[epoch: 1, batch:   3900] loss: 1.02018 time load: 0.07238 time model: 0.32318
[epoch: 1, batch:   4000] loss: 1.16277 time load: 0.06622 time model: 0.31977
[epoch: 1, batch:   4100] loss: 1.06247 time load: 0.06970 time model: 0.31661
[epoch: 1, batch:   4200] loss: 1.03313 time load: 0.06984 time model: 0.32934
[epoch: 1, batch:   4300] loss: 1.04979 time load: 0.06936 time model: 0.31727
[epoch: 1, batch:   4400] loss: 1.32583 time load: 0.06312 time model: 0.32094
[epoch: 1, batch:   4500] loss: 1.10369 time load: 0.07107 time model: 0.31646
[epoch: 1, batch:   4600] loss: 1.07863 time load: 0.06989 time model: 0.32236
[epoch: 1, batch:   4700] loss: 1.06326 time load: 0.07141 time model: 0.32424
[epoch: 1, batch:   4800] loss: 0.99412 time load: 0.06939 time model: 0.32393
[epoch: 1, batch:   4900] loss: 1.17583 time load: 0.06752 time model: 0.32481
[epoch: 1, batch:   5000] loss: 0.97960 time load: 0.06811 time model: 0.32272
Epoch: 1/100 Loss: 1.1700482172997224 Train MSESteer: 4208.59 Train MSESpeed: 23.823 MSESteer: 1334.326 MSESpeed: 15.413
[epoch: 2, batch:    100] loss: 1.07467 time load: 0.05568 time model: 0.31712
[epoch: 2, batch:    200] loss: 0.90984 time load: 0.06337 time model: 0.31903
[epoch: 2, batch:    300] loss: 0.99983 time load: 0.05642 time model: 0.32545
[epoch: 2, batch:    400] loss: 0.97789 time load: 0.06864 time model: 0.31939
[epoch: 2, batch:    500] loss: 1.15786 time load: 0.05565 time model: 0.31714
[epoch: 2, batch:    600] loss: 1.17361 time load: 0.06634 time model: 0.32577
[epoch: 2, batch:    700] loss: 1.04086 time load: 0.05503 time model: 0.31817
[epoch: 2, batch:    800] loss: 1.01654 time load: 0.06491 time model: 0.32355
[epoch: 2, batch:    900] loss: 1.09313 time load: 0.05553 time model: 0.32092
[epoch: 2, batch:   1000] loss: 0.98462 time load: 0.06839 time model: 0.31838
[epoch: 2, batch:   1100] loss: 1.02790 time load: 0.05478 time model: 0.32647
[epoch: 2, batch:   1200] loss: 0.90598 time load: 0.06997 time model: 0.32119
[epoch: 2, batch:   1300] loss: 0.94612 time load: 0.05462 time model: 0.32298
[epoch: 2, batch:   1400] loss: 0.93650 time load: 0.06225 time model: 0.32207
[epoch: 2, batch:   1500] loss: 1.10441 time load: 0.05640 time model: 0.31579
[epoch: 2, batch:   1600] loss: 0.88130 time load: 0.06750 time model: 0.31942
[epoch: 2, batch:   1700] loss: 0.94762 time load: 0.05494 time model: 0.31551
[epoch: 2, batch:   1800] loss: 0.92109 time load: 0.06415 time model: 0.31679
[epoch: 2, batch:   1900] loss: 1.04743 time load: 0.05543 time model: 0.31691
[epoch: 2, batch:   2000] loss: 1.14857 time load: 0.06473 time model: 0.32118
[epoch: 2, batch:   2100] loss: 1.04693 time load: 0.05623 time model: 0.32227
[epoch: 2, batch:   2200] loss: 0.95583 time load: 0.06420 time model: 0.31565
[epoch: 2, batch:   2300] loss: 0.81660 time load: 0.05443 time model: 0.31913
[epoch: 2, batch:   2400] loss: 0.97991 time load: 0.06602 time model: 0.32218
[epoch: 2, batch:   2500] loss: 1.05815 time load: 0.05717 time model: 0.31527
[epoch: 2, batch:   2600] loss: 0.98449 time load: 0.06296 time model: 0.32260
[epoch: 2, batch:   2700] loss: 1.09547 time load: 0.05514 time model: 0.32197
[epoch: 2, batch:   2800] loss: 0.93497 time load: 0.06313 time model: 0.32190
[epoch: 2, batch:   2900] loss: 1.01961 time load: 0.05588 time model: 0.31881
[epoch: 2, batch:   3000] loss: 0.94452 time load: 0.06376 time model: 0.31938
[epoch: 2, batch:   3100] loss: 1.06682 time load: 0.05499 time model: 0.32024
[epoch: 2, batch:   3200] loss: 1.01776 time load: 0.07094 time model: 0.31944
[epoch: 2, batch:   3300] loss: 0.84361 time load: 0.05405 time model: 0.32134
[epoch: 2, batch:   3400] loss: 1.05991 time load: 0.06455 time model: 0.32027
[epoch: 2, batch:   3500] loss: 0.86864 time load: 0.05485 time model: 0.31907
[epoch: 2, batch:   3600] loss: 0.91230 time load: 0.06215 time model: 0.31686
[epoch: 2, batch:   3700] loss: 0.91581 time load: 0.05464 time model: 0.31563
[epoch: 2, batch:   3800] loss: 1.00861 time load: 0.05395 time model: 0.32048
[epoch: 2, batch:   3900] loss: 0.92254 time load: 0.05520 time model: 0.32093
[epoch: 2, batch:   4000] loss: 1.12309 time load: 0.05633 time model: 0.31942
[epoch: 2, batch:   4100] loss: 0.98378 time load: 0.10125 time model: 0.31890
[epoch: 2, batch:   4200] loss: 0.83990 time load: 0.05497 time model: 0.31865
[epoch: 2, batch:   4300] loss: 0.93007 time load: 0.10367 time model: 0.31521
[epoch: 2, batch:   4400] loss: 0.87010 time load: 0.05476 time model: 0.31862
[epoch: 2, batch:   4500] loss: 0.96717 time load: 0.09625 time model: 0.31864
[epoch: 2, batch:   4600] loss: 1.00532 time load: 0.05383 time model: 0.32171
[epoch: 2, batch:   4700] loss: 1.05580 time load: 0.10668 time model: 0.32351
[epoch: 2, batch:   4800] loss: 1.00609 time load: 0.05517 time model: 0.31738
[epoch: 2, batch:   4900] loss: 0.92516 time load: 0.06380 time model: 0.32680
[epoch: 2, batch:   5000] loss: 1.15107 time load: 0.06286 time model: 0.32352
Epoch: 2/100 Loss: 0.9919490641054582 Train MSESteer: 4098.507 Train MSESpeed: 14.168 MSESteer: 1491.263 MSESpeed: 15.026
[epoch: 3, batch:    100] loss: 0.88003 time load: 0.05664 time model: 0.31753
[epoch: 3, batch:    200] loss: 1.04565 time load: 0.06402 time model: 0.31894
[epoch: 3, batch:    300] loss: 0.90768 time load: 0.05658 time model: 0.32070
[epoch: 3, batch:    400] loss: 0.93547 time load: 0.05400 time model: 0.32260
[epoch: 3, batch:    500] loss: 0.85340 time load: 0.05569 time model: 0.31799
[epoch: 3, batch:    600] loss: 0.82557 time load: 0.05444 time model: 0.31775
[epoch: 3, batch:    700] loss: 0.92577 time load: 0.05473 time model: 0.31687
[epoch: 3, batch:    800] loss: 0.85578 time load: 0.05584 time model: 0.32200
[epoch: 3, batch:    900] loss: 1.01237 time load: 0.05645 time model: 0.31816
[epoch: 3, batch:   1000] loss: 0.77169 time load: 0.05449 time model: 0.31412
[epoch: 3, batch:   1100] loss: 0.77024 time load: 0.05527 time model: 0.31761
[epoch: 3, batch:   1200] loss: 0.80554 time load: 0.05395 time model: 0.31792
[epoch: 3, batch:   1300] loss: 0.94507 time load: 0.05688 time model: 0.31656
[epoch: 3, batch:   1400] loss: 1.06310 time load: 0.05397 time model: 0.31530
[epoch: 3, batch:   1500] loss: 0.82995 time load: 0.10227 time model: 0.31149
[epoch: 3, batch:   1600] loss: 0.75247 time load: 0.05587 time model: 0.31616
[epoch: 3, batch:   1700] loss: 0.90204 time load: 0.06521 time model: 0.31947
[epoch: 3, batch:   1800] loss: 1.10322 time load: 0.05496 time model: 0.32095
[epoch: 3, batch:   1900] loss: 0.86238 time load: 0.06694 time model: 0.31842
[epoch: 3, batch:   2000] loss: 0.88431 time load: 0.05471 time model: 0.31810
[epoch: 3, batch:   2100] loss: 0.88044 time load: 0.06463 time model: 0.31822
[epoch: 3, batch:   2200] loss: 0.88115 time load: 0.05597 time model: 0.31442
[epoch: 3, batch:   2300] loss: 0.91071 time load: 0.06753 time model: 0.32039
[epoch: 3, batch:   2400] loss: 0.88206 time load: 0.06073 time model: 0.32383
[epoch: 3, batch:   2500] loss: 0.84541 time load: 0.06535 time model: 0.32181
[epoch: 3, batch:   2600] loss: 0.86455 time load: 0.05404 time model: 0.31522
[epoch: 3, batch:   2700] loss: 0.98055 time load: 0.06558 time model: 0.32124
[epoch: 3, batch:   2800] loss: 0.86559 time load: 0.05294 time model: 0.32244
[epoch: 3, batch:   2900] loss: 0.87607 time load: 0.06967 time model: 0.31947
[epoch: 3, batch:   3000] loss: 0.67611 time load: 0.05435 time model: 0.31617
[epoch: 3, batch:   3100] loss: 0.81244 time load: 0.06437 time model: 0.32364
[epoch: 3, batch:   3200] loss: 0.92411 time load: 0.05450 time model: 0.31595
[epoch: 3, batch:   3300] loss: 0.77543 time load: 0.06602 time model: 0.31471
[epoch: 3, batch:   3400] loss: 0.90137 time load: 0.05384 time model: 0.31604
[epoch: 3, batch:   3500] loss: 0.72773 time load: 0.06540 time model: 0.32103
[epoch: 3, batch:   3600] loss: 0.75719 time load: 0.06287 time model: 0.31756
[epoch: 3, batch:   3700] loss: 0.96806 time load: 0.06778 time model: 0.31480
[epoch: 3, batch:   3800] loss: 0.80641 time load: 0.05521 time model: 0.32258
[epoch: 3, batch:   3900] loss: 0.82364 time load: 0.06460 time model: 0.31712
[epoch: 3, batch:   4000] loss: 0.99244 time load: 0.05253 time model: 0.31642
[epoch: 3, batch:   4100] loss: 0.71364 time load: 0.06620 time model: 0.31579
[epoch: 3, batch:   4200] loss: 0.90120 time load: 0.05452 time model: 0.32160
[epoch: 3, batch:   4300] loss: 0.92273 time load: 0.06504 time model: 0.31896
[epoch: 3, batch:   4400] loss: 0.84010 time load: 0.05541 time model: 0.32148
[epoch: 3, batch:   4500] loss: 0.91247 time load: 0.06417 time model: 0.31661
[epoch: 3, batch:   4600] loss: 1.00962 time load: 0.05337 time model: 0.31836
[epoch: 3, batch:   4700] loss: 0.69146 time load: 0.06547 time model: 0.31991
[epoch: 3, batch:   4800] loss: 0.81864 time load: 0.05372 time model: 0.32096
[epoch: 3, batch:   4900] loss: 0.74270 time load: 0.06832 time model: 0.31781
[epoch: 3, batch:   5000] loss: 0.89058 time load: 0.05441 time model: 0.31926
Epoch: 3/100 Loss: 0.8708557080454475 Train MSESteer: 3679.745 Train MSESpeed: 11.512 MSESteer: 1040.523 MSESpeed: 13.848
[epoch: 4, batch:    100] loss: 0.79462 time load: 0.05412 time model: 0.31603
[epoch: 4, batch:    200] loss: 0.86648 time load: 0.06570 time model: 0.32255
[epoch: 4, batch:    300] loss: 0.89244 time load: 0.05661 time model: 0.32060
[epoch: 4, batch:    400] loss: 0.65346 time load: 0.06445 time model: 0.32131
[epoch: 4, batch:    500] loss: 0.72571 time load: 0.05501 time model: 0.32291
[epoch: 4, batch:    600] loss: 0.75183 time load: 0.05726 time model: 0.33567
[epoch: 4, batch:    700] loss: 0.64505 time load: 0.05508 time model: 0.31784
[epoch: 4, batch:    800] loss: 0.69089 time load: 0.05749 time model: 0.31750
[epoch: 4, batch:    900] loss: 0.77136 time load: 0.05560 time model: 0.31678
[epoch: 4, batch:   1000] loss: 0.84671 time load: 0.05757 time model: 0.32098
[epoch: 4, batch:   1100] loss: 0.87759 time load: 0.05676 time model: 0.32359
[epoch: 4, batch:   1200] loss: 0.69972 time load: 0.05797 time model: 0.31528
[epoch: 4, batch:   1300] loss: 0.79280 time load: 0.05707 time model: 0.31883
[epoch: 4, batch:   1400] loss: 0.84279 time load: 0.06050 time model: 0.32456
[epoch: 4, batch:   1500] loss: 0.84524 time load: 0.05653 time model: 0.32092
[epoch: 4, batch:   1600] loss: 0.90561 time load: 0.05829 time model: 0.32378
[epoch: 4, batch:   1700] loss: 0.83007 time load: 0.05558 time model: 0.31419
[epoch: 4, batch:   1800] loss: 0.79987 time load: 0.05877 time model: 0.31840
[epoch: 4, batch:   1900] loss: 0.91787 time load: 0.05796 time model: 0.31617
[epoch: 4, batch:   2000] loss: 0.72325 time load: 0.05890 time model: 0.32798
[epoch: 4, batch:   2100] loss: 0.79924 time load: 0.06868 time model: 0.33194
[epoch: 4, batch:   2200] loss: 1.01659 time load: 0.05909 time model: 0.31842
[epoch: 4, batch:   2300] loss: 0.71010 time load: 0.07393 time model: 0.32369
[epoch: 4, batch:   2400] loss: 0.76696 time load: 0.05896 time model: 0.32121
[epoch: 4, batch:   2500] loss: 0.89394 time load: 0.06975 time model: 0.32827
[epoch: 4, batch:   2600] loss: 0.72954 time load: 0.05898 time model: 0.32070
[epoch: 4, batch:   2700] loss: 0.77601 time load: 0.06630 time model: 0.32085
[epoch: 4, batch:   2800] loss: 0.72933 time load: 0.05862 time model: 0.31769
[epoch: 4, batch:   2900] loss: 0.65813 time load: 0.07071 time model: 0.31950
[epoch: 4, batch:   3000] loss: 0.76288 time load: 0.05845 time model: 0.32079
[epoch: 4, batch:   3100] loss: 0.96554 time load: 0.06507 time model: 0.31862
[epoch: 4, batch:   3200] loss: 0.70693 time load: 0.06046 time model: 0.32614
[epoch: 4, batch:   3300] loss: 0.69526 time load: 0.06419 time model: 0.32186
[epoch: 4, batch:   3400] loss: 0.75122 time load: 0.05834 time model: 0.31823
[epoch: 4, batch:   3500] loss: 0.75736 time load: 0.06514 time model: 0.31858
[epoch: 4, batch:   3600] loss: 0.87045 time load: 0.05965 time model: 0.32410
[epoch: 4, batch:   3700] loss: 0.77255 time load: 0.06440 time model: 0.31937
[epoch: 4, batch:   3800] loss: 0.72239 time load: 0.05971 time model: 0.31652
[epoch: 4, batch:   3900] loss: 0.88628 time load: 0.06418 time model: 0.32470
[epoch: 4, batch:   4000] loss: 0.71366 time load: 0.06703 time model: 0.31802
[epoch: 4, batch:   4100] loss: 0.79448 time load: 0.06990 time model: 0.31924
[epoch: 4, batch:   4200] loss: 0.96452 time load: 0.06814 time model: 0.31635
[epoch: 4, batch:   4300] loss: 0.81667 time load: 0.06922 time model: 0.33082
[epoch: 4, batch:   4400] loss: 0.68808 time load: 0.06183 time model: 0.31914
[epoch: 4, batch:   4500] loss: 0.73854 time load: 0.07275 time model: 0.32230
[epoch: 4, batch:   4600] loss: 0.77343 time load: 0.05812 time model: 0.32485
[epoch: 4, batch:   4700] loss: 0.68949 time load: 0.07006 time model: 0.31930
[epoch: 4, batch:   4800] loss: 0.76926 time load: 0.05903 time model: 0.31742
[epoch: 4, batch:   4900] loss: 0.66724 time load: 0.06661 time model: 0.32161
[epoch: 4, batch:   5000] loss: 0.81738 time load: 0.05960 time model: 0.31813
Epoch: 4/100 Loss: 0.7872584078633804 Train MSESteer: 3348.825 Train MSESpeed: 10.126 MSESteer: 1027.143 MSESpeed: 12.645
[epoch: 5, batch:    100] loss: 0.92730 time load: 0.06230 time model: 0.31709
[epoch: 5, batch:    200] loss: 0.77677 time load: 0.06298 time model: 0.31787
[epoch: 5, batch:    300] loss: 0.59452 time load: 0.05556 time model: 0.31806
[epoch: 5, batch:    400] loss: 0.63293 time load: 0.06284 time model: 0.32207
[epoch: 5, batch:    500] loss: 0.80652 time load: 0.05553 time model: 0.32243
[epoch: 5, batch:    600] loss: 0.68827 time load: 0.06537 time model: 0.31927
[epoch: 5, batch:    700] loss: 0.74259 time load: 0.05496 time model: 0.31984
[epoch: 5, batch:    800] loss: 0.69408 time load: 0.06479 time model: 0.32312
[epoch: 5, batch:    900] loss: 0.78600 time load: 0.05541 time model: 0.32298
[epoch: 5, batch:   1000] loss: 0.78720 time load: 0.06258 time model: 0.31767
[epoch: 5, batch:   1100] loss: 0.69845 time load: 0.10628 time model: 0.32365
[epoch: 5, batch:   1200] loss: 0.92021 time load: 0.05367 time model: 0.32053
[epoch: 5, batch:   1300] loss: 0.73582 time load: 0.11137 time model: 0.32037
[epoch: 5, batch:   1400] loss: 0.64039 time load: 0.05443 time model: 0.32319
[epoch: 5, batch:   1500] loss: 0.64018 time load: 0.10363 time model: 0.32414
[epoch: 5, batch:   1600] loss: 0.66134 time load: 0.05468 time model: 0.31528
[epoch: 5, batch:   1700] loss: 0.60321 time load: 0.10458 time model: 0.31963
[epoch: 5, batch:   1800] loss: 0.74351 time load: 0.06032 time model: 0.31644
[epoch: 5, batch:   1900] loss: 0.78106 time load: 0.10823 time model: 0.31771
[epoch: 5, batch:   2000] loss: 0.74990 time load: 0.05403 time model: 0.31751
[epoch: 5, batch:   2100] loss: 0.64217 time load: 0.11376 time model: 0.33066
[epoch: 5, batch:   2200] loss: 0.61235 time load: 0.05463 time model: 0.32122
[epoch: 5, batch:   2300] loss: 0.73138 time load: 0.10236 time model: 0.32307
[epoch: 5, batch:   2400] loss: 0.58797 time load: 0.05389 time model: 0.31959
[epoch: 5, batch:   2500] loss: 0.62067 time load: 0.10710 time model: 0.31699
[epoch: 5, batch:   2600] loss: 0.73533 time load: 0.05325 time model: 0.32327
[epoch: 5, batch:   2700] loss: 0.96271 time load: 0.11005 time model: 0.33403
[epoch: 5, batch:   2800] loss: 0.95664 time load: 0.05307 time model: 0.32252
[epoch: 5, batch:   2900] loss: 0.66622 time load: 0.10183 time model: 0.31783
[epoch: 5, batch:   3000] loss: 0.87798 time load: 0.05594 time model: 0.32164
[epoch: 5, batch:   3100] loss: 0.70840 time load: 0.10262 time model: 0.31742
[epoch: 5, batch:   3200] loss: 0.75129 time load: 0.05407 time model: 0.32088
[epoch: 5, batch:   3300] loss: 0.69783 time load: 0.10934 time model: 0.32029
[epoch: 5, batch:   3400] loss: 0.60525 time load: 0.05401 time model: 0.31653
[epoch: 5, batch:   3500] loss: 0.63262 time load: 0.10401 time model: 0.31780
[epoch: 5, batch:   3600] loss: 0.65309 time load: 0.05496 time model: 0.32512
[epoch: 5, batch:   3700] loss: 0.70336 time load: 0.10966 time model: 0.31690
[epoch: 5, batch:   3800] loss: 0.71196 time load: 0.05185 time model: 0.31678
[epoch: 5, batch:   3900] loss: 0.67915 time load: 0.10566 time model: 0.31990
[epoch: 5, batch:   4000] loss: 0.61054 time load: 0.05810 time model: 0.32102
[epoch: 5, batch:   4100] loss: 0.71982 time load: 0.10505 time model: 0.31549
[epoch: 5, batch:   4200] loss: 0.59096 time load: 0.05249 time model: 0.31591
[epoch: 5, batch:   4300] loss: 0.76684 time load: 0.11327 time model: 0.32105
[epoch: 5, batch:   4400] loss: 0.74746 time load: 0.05297 time model: 0.31619
[epoch: 5, batch:   4500] loss: 0.71424 time load: 0.10288 time model: 0.32589
[epoch: 5, batch:   4600] loss: 0.67160 time load: 0.05333 time model: 0.32665
[epoch: 5, batch:   4700] loss: 0.90634 time load: 0.11620 time model: 0.33116
[epoch: 5, batch:   4800] loss: 0.68761 time load: 0.05347 time model: 0.32458
[epoch: 5, batch:   4900] loss: 0.75302 time load: 0.06846 time model: 0.32279
[epoch: 5, batch:   5000] loss: 0.73680 time load: 0.05278 time model: 0.31797
Epoch: 5/100 Loss: 0.7204298868684851 Train MSESteer: 3071.553 Train MSESpeed: 9.211 MSESteer: 920.24 MSESpeed: 9.409
[epoch: 6, batch:    100] loss: 0.67959 time load: 0.06268 time model: 0.31822
[epoch: 6, batch:    200] loss: 0.71846 time load: 0.06845 time model: 0.31540
[epoch: 6, batch:    300] loss: 0.67006 time load: 0.06674 time model: 0.32092
[epoch: 6, batch:    400] loss: 0.64880 time load: 0.06054 time model: 0.32721
[epoch: 6, batch:    500] loss: 0.74902 time load: 0.06720 time model: 0.32249
[epoch: 6, batch:    600] loss: 0.68802 time load: 0.06242 time model: 0.31888
[epoch: 6, batch:    700] loss: 0.71974 time load: 0.06507 time model: 0.31778
[epoch: 6, batch:    800] loss: 0.62957 time load: 0.06518 time model: 0.32518
[epoch: 6, batch:    900] loss: 0.68073 time load: 0.07020 time model: 0.31586
[epoch: 6, batch:   1000] loss: 0.53976 time load: 0.06223 time model: 0.31584
[epoch: 6, batch:   1100] loss: 0.65834 time load: 0.06032 time model: 0.31423
[epoch: 6, batch:   1200] loss: 0.66898 time load: 0.06723 time model: 0.31639
[epoch: 6, batch:   1300] loss: 0.67951 time load: 0.06755 time model: 0.31855
[epoch: 6, batch:   1400] loss: 0.61438 time load: 0.06541 time model: 0.31947
[epoch: 6, batch:   1500] loss: 0.63748 time load: 0.06747 time model: 0.32401
[epoch: 6, batch:   1600] loss: 0.71065 time load: 0.06331 time model: 0.32606
[epoch: 6, batch:   1700] loss: 0.63293 time load: 0.06662 time model: 0.32012
[epoch: 6, batch:   1800] loss: 0.82126 time load: 0.05979 time model: 0.30988
[epoch: 6, batch:   1900] loss: 0.50247 time load: 0.06302 time model: 0.31007
[epoch: 6, batch:   2000] loss: 0.65239 time load: 0.06335 time model: 0.31946
[epoch: 6, batch:   2100] loss: 0.59773 time load: 0.07151 time model: 0.31977
[epoch: 6, batch:   2200] loss: 0.59913 time load: 0.06511 time model: 0.31195
[epoch: 6, batch:   2300] loss: 0.59935 time load: 0.07052 time model: 0.31700
[epoch: 6, batch:   2400] loss: 0.57597 time load: 0.06437 time model: 0.32211
[epoch: 6, batch:   2500] loss: 0.75004 time load: 0.06832 time model: 0.31785
[epoch: 6, batch:   2600] loss: 0.57425 time load: 0.06600 time model: 0.32219
[epoch: 6, batch:   2700] loss: 0.72647 time load: 0.06615 time model: 0.32341
[epoch: 6, batch:   2800] loss: 0.73378 time load: 0.06601 time model: 0.32131
[epoch: 6, batch:   2900] loss: 0.76496 time load: 0.06573 time model: 0.31978
[epoch: 6, batch:   3000] loss: 0.58304 time load: 0.06245 time model: 0.32235
[epoch: 6, batch:   3100] loss: 0.61391 time load: 0.06549 time model: 0.32895
[epoch: 6, batch:   3200] loss: 0.77997 time load: 0.06291 time model: 0.31803
[epoch: 6, batch:   3300] loss: 0.54696 time load: 0.06753 time model: 0.32193
[epoch: 6, batch:   3400] loss: 0.60061 time load: 0.05585 time model: 0.32008
[epoch: 6, batch:   3500] loss: 0.49490 time load: 0.06612 time model: 0.32708
[epoch: 6, batch:   3600] loss: 0.68679 time load: 0.05493 time model: 0.31926
[epoch: 6, batch:   3700] loss: 0.69748 time load: 0.06613 time model: 0.32196
[epoch: 6, batch:   3800] loss: 0.57236 time load: 0.05549 time model: 0.33380
[epoch: 6, batch:   3900] loss: 0.57984 time load: 0.06659 time model: 0.32109
[epoch: 6, batch:   4000] loss: 0.70200 time load: 0.05949 time model: 0.31861
[epoch: 6, batch:   4100] loss: 0.61278 time load: 0.06632 time model: 0.32652
[epoch: 6, batch:   4200] loss: 0.73462 time load: 0.05471 time model: 0.32391
[epoch: 6, batch:   4300] loss: 0.66125 time load: 0.06893 time model: 0.32296
[epoch: 6, batch:   4400] loss: 0.50852 time load: 0.05614 time model: 0.32651
[epoch: 6, batch:   4500] loss: 0.62429 time load: 0.05953 time model: 0.32772
[epoch: 6, batch:   4600] loss: 0.73436 time load: 0.05566 time model: 0.33481
[epoch: 6, batch:   4700] loss: 0.81241 time load: 0.06490 time model: 0.32349
[epoch: 6, batch:   4800] loss: 0.68891 time load: 0.05657 time model: 0.31733
[epoch: 6, batch:   4900] loss: 0.60522 time load: 0.05621 time model: 0.30875
[epoch: 6, batch:   5000] loss: 0.63985 time load: 0.05476 time model: 0.31700
Epoch: 6/100 Loss: 0.654463765516156 Train MSESteer: 2767.622 Train MSESpeed: 8.619 MSESteer: 861.066 MSESpeed: 9.332
[epoch: 7, batch:    100] loss: 0.55944 time load: 0.05494 time model: 0.31640
[epoch: 7, batch:    200] loss: 0.69488 time load: 0.06441 time model: 0.32511
[epoch: 7, batch:    300] loss: 0.72222 time load: 0.05331 time model: 0.31710
[epoch: 7, batch:    400] loss: 0.59167 time load: 0.06363 time model: 0.31809
[epoch: 7, batch:    500] loss: 0.47230 time load: 0.05285 time model: 0.31793
[epoch: 7, batch:    600] loss: 0.56301 time load: 0.06451 time model: 0.32209
[epoch: 7, batch:    700] loss: 0.67942 time load: 0.05480 time model: 0.31789
[epoch: 7, batch:    800] loss: 0.68511 time load: 0.06482 time model: 0.31698
[epoch: 7, batch:    900] loss: 0.63442 time load: 0.05108 time model: 0.31655
[epoch: 7, batch:   1000] loss: 0.55760 time load: 0.05301 time model: 0.30932
[epoch: 7, batch:   1100] loss: 0.59211 time load: 0.11346 time model: 0.31646
[epoch: 7, batch:   1200] loss: 0.59288 time load: 0.05462 time model: 0.32883
[epoch: 7, batch:   1300] loss: 0.69181 time load: 0.12283 time model: 0.31408
[epoch: 7, batch:   1400] loss: 0.59097 time load: 0.05445 time model: 0.31585
[epoch: 7, batch:   1500] loss: 0.71806 time load: 0.10909 time model: 0.31676
[epoch: 7, batch:   1600] loss: 0.59988 time load: 0.05505 time model: 0.32155
[epoch: 7, batch:   1700] loss: 0.54087 time load: 0.11040 time model: 0.31711
[epoch: 7, batch:   1800] loss: 0.52557 time load: 0.05477 time model: 0.32331
[epoch: 7, batch:   1900] loss: 0.60589 time load: 0.06115 time model: 0.31759
[epoch: 7, batch:   2000] loss: 0.70344 time load: 0.05512 time model: 0.32041
[epoch: 7, batch:   2100] loss: 0.55308 time load: 0.06344 time model: 0.31289
[epoch: 7, batch:   2200] loss: 0.48798 time load: 0.05562 time model: 0.31220
[epoch: 7, batch:   2300] loss: 0.60280 time load: 0.06620 time model: 0.32970
[epoch: 7, batch:   2400] loss: 0.48076 time load: 0.05422 time model: 0.31890
[epoch: 7, batch:   2500] loss: 0.68038 time load: 0.06311 time model: 0.32143
[epoch: 7, batch:   2600] loss: 0.56899 time load: 0.05560 time model: 0.31472
[epoch: 7, batch:   2700] loss: 0.60481 time load: 0.06522 time model: 0.31678
[epoch: 7, batch:   2800] loss: 0.66101 time load: 0.05678 time model: 0.32484
[epoch: 7, batch:   2900] loss: 0.82179 time load: 0.06381 time model: 0.32058
[epoch: 7, batch:   3000] loss: 0.65080 time load: 0.05652 time model: 0.32196
[epoch: 7, batch:   3100] loss: 0.54999 time load: 0.06268 time model: 0.32732
[epoch: 7, batch:   3200] loss: 0.56886 time load: 0.05534 time model: 0.32087
[epoch: 7, batch:   3300] loss: 0.56410 time load: 0.07173 time model: 0.31417
[epoch: 7, batch:   3400] loss: 0.60467 time load: 0.05773 time model: 0.31647
[epoch: 7, batch:   3500] loss: 0.55131 time load: 0.06249 time model: 0.32703
[epoch: 7, batch:   3600] loss: 0.53499 time load: 0.05542 time model: 0.31623
[epoch: 7, batch:   3700] loss: 0.50791 time load: 0.06646 time model: 0.32614
[epoch: 7, batch:   3800] loss: 0.52832 time load: 0.06417 time model: 0.32035
[epoch: 7, batch:   3900] loss: 0.56288 time load: 0.06327 time model: 0.32254
[epoch: 7, batch:   4000] loss: 0.61431 time load: 0.05563 time model: 0.31984
[epoch: 7, batch:   4100] loss: 0.61973 time load: 0.06375 time model: 0.32020
[epoch: 7, batch:   4200] loss: 0.51918 time load: 0.05546 time model: 0.31791
[epoch: 7, batch:   4300] loss: 0.55016 time load: 0.06393 time model: 0.31938
[epoch: 7, batch:   4400] loss: 0.58119 time load: 0.05597 time model: 0.31898
[epoch: 7, batch:   4500] loss: 0.66805 time load: 0.05946 time model: 0.31603
[epoch: 7, batch:   4600] loss: 0.63785 time load: 0.05501 time model: 0.31589
[epoch: 7, batch:   4700] loss: 0.60238 time load: 0.06263 time model: 0.32287
[epoch: 7, batch:   4800] loss: 0.54185 time load: 0.05392 time model: 0.31865
[epoch: 7, batch:   4900] loss: 0.59663 time load: 0.06447 time model: 0.32114
[epoch: 7, batch:   5000] loss: 0.54608 time load: 0.05613 time model: 0.31581
Epoch: 7/100 Loss: 0.5975935417558539 Train MSESteer: 2515.503 Train MSESpeed: 8.009 MSESteer: 784.57 MSESpeed: 8.855
[epoch: 8, batch:    100] loss: 0.64704 time load: 0.07015 time model: 0.32679
[epoch: 8, batch:    200] loss: 0.59369 time load: 0.06314 time model: 0.32050
[epoch: 8, batch:    300] loss: 0.69932 time load: 0.07200 time model: 0.32022
[epoch: 8, batch:    400] loss: 0.51744 time load: 0.06236 time model: 0.31909
[epoch: 8, batch:    500] loss: 0.44945 time load: 0.06614 time model: 0.32004
[epoch: 8, batch:    600] loss: 0.54995 time load: 0.06250 time model: 0.32033
[epoch: 8, batch:    700] loss: 0.70282 time load: 0.06378 time model: 0.32041
[epoch: 8, batch:    800] loss: 0.56412 time load: 0.06485 time model: 0.31807
[epoch: 8, batch:    900] loss: 0.56832 time load: 0.06326 time model: 0.31906
[epoch: 8, batch:   1000] loss: 0.39249 time load: 0.06571 time model: 0.32400
[epoch: 8, batch:   1100] loss: 0.60690 time load: 0.06352 time model: 0.31625
[epoch: 8, batch:   1200] loss: 0.49223 time load: 0.05570 time model: 0.32402
[epoch: 8, batch:   1300] loss: 0.59921 time load: 0.05718 time model: 0.31868
[epoch: 8, batch:   1400] loss: 0.65159 time load: 0.05605 time model: 0.33590
[epoch: 8, batch:   1500] loss: 0.71094 time load: 0.05359 time model: 0.32167
[epoch: 8, batch:   1600] loss: 0.47582 time load: 0.05795 time model: 0.31743
[epoch: 8, batch:   1700] loss: 0.54679 time load: 0.06179 time model: 0.31554
[epoch: 8, batch:   1800] loss: 0.62825 time load: 0.05475 time model: 0.31659
[epoch: 8, batch:   1900] loss: 0.61373 time load: 0.06098 time model: 0.31483
[epoch: 8, batch:   2000] loss: 0.50791 time load: 0.05503 time model: 0.31545
[epoch: 8, batch:   2100] loss: 0.69907 time load: 0.06068 time model: 0.31793
[epoch: 8, batch:   2200] loss: 0.55504 time load: 0.05294 time model: 0.31970
[epoch: 8, batch:   2300] loss: 0.53505 time load: 0.06782 time model: 0.32571
[epoch: 8, batch:   2400] loss: 0.58009 time load: 0.05586 time model: 0.31916
[epoch: 8, batch:   2500] loss: 0.60358 time load: 0.06431 time model: 0.32417
[epoch: 8, batch:   2600] loss: 0.63826 time load: 0.05569 time model: 0.31703
[epoch: 8, batch:   2700] loss: 0.61044 time load: 0.06442 time model: 0.32675
[epoch: 8, batch:   2800] loss: 0.72944 time load: 0.05507 time model: 0.32154
[epoch: 8, batch:   2900] loss: 0.58175 time load: 0.06377 time model: 0.32131
[epoch: 8, batch:   3000] loss: 0.74918 time load: 0.05732 time model: 0.32289
[epoch: 8, batch:   3100] loss: 0.37166 time load: 0.06721 time model: 0.31886
[epoch: 8, batch:   3200] loss: 0.59362 time load: 0.05760 time model: 0.31732
[epoch: 8, batch:   3300] loss: 0.65132 time load: 0.06378 time model: 0.32311
[epoch: 8, batch:   3400] loss: 0.47914 time load: 0.05742 time model: 0.32089
[epoch: 8, batch:   3500] loss: 0.59866 time load: 0.06565 time model: 0.31684
[epoch: 8, batch:   3600] loss: 0.51993 time load: 0.05498 time model: 0.31912
[epoch: 8, batch:   3700] loss: 0.53436 time load: 0.06650 time model: 0.32354
[epoch: 8, batch:   3800] loss: 0.63016 time load: 0.05380 time model: 0.31144
[epoch: 8, batch:   3900] loss: 0.62692 time load: 0.06253 time model: 0.31981
[epoch: 8, batch:   4000] loss: 0.56618 time load: 0.05652 time model: 0.31978
[epoch: 8, batch:   4100] loss: 0.65596 time load: 0.06780 time model: 0.31870
[epoch: 8, batch:   4200] loss: 0.51150 time load: 0.05321 time model: 0.31426
[epoch: 8, batch:   4300] loss: 0.43957 time load: 0.06570 time model: 0.31091
[epoch: 8, batch:   4400] loss: 0.56470 time load: 0.05353 time model: 0.31455
[epoch: 8, batch:   4500] loss: 0.60455 time load: 0.06337 time model: 0.31820
[epoch: 8, batch:   4600] loss: 0.63390 time load: 0.05629 time model: 0.32201
[epoch: 8, batch:   4700] loss: 0.43862 time load: 0.06566 time model: 0.32151
[epoch: 8, batch:   4800] loss: 0.59913 time load: 0.05769 time model: 0.32347
[epoch: 8, batch:   4900] loss: 0.40693 time load: 0.06410 time model: 0.31659
[epoch: 8, batch:   5000] loss: 0.67741 time load: 0.05710 time model: 0.31599
Epoch: 8/100 Loss: 0.5778829726933827 Train MSESteer: 2418.511 Train MSESpeed: 7.904 MSESteer: 875.316 MSESpeed: 8.866
[epoch: 9, batch:    100] loss: 0.64575 time load: 0.06758 time model: 0.32469
[epoch: 9, batch:    200] loss: 0.49284 time load: 0.07037 time model: 0.31922
[epoch: 9, batch:    300] loss: 0.55642 time load: 0.06414 time model: 0.31780
[epoch: 9, batch:    400] loss: 0.52201 time load: 0.05540 time model: 0.32489
[epoch: 9, batch:    500] loss: 0.54023 time load: 0.06865 time model: 0.32571
[epoch: 9, batch:    600] loss: 0.62575 time load: 0.05613 time model: 0.31681
[epoch: 9, batch:    700] loss: 0.53392 time load: 0.06375 time model: 0.32258
[epoch: 9, batch:    800] loss: 0.60158 time load: 0.05751 time model: 0.32577
[epoch: 9, batch:    900] loss: 0.55711 time load: 0.06429 time model: 0.32255
[epoch: 9, batch:   1000] loss: 0.63598 time load: 0.05348 time model: 0.32129
[epoch: 9, batch:   1100] loss: 0.56271 time load: 0.06538 time model: 0.31975
[epoch: 9, batch:   1200] loss: 0.58440 time load: 0.05639 time model: 0.32921
[epoch: 9, batch:   1300] loss: 0.56442 time load: 0.06669 time model: 0.31971
[epoch: 9, batch:   1400] loss: 0.56730 time load: 0.05737 time model: 0.32280
[epoch: 9, batch:   1500] loss: 0.45894 time load: 0.06423 time model: 0.31373
[epoch: 9, batch:   1600] loss: 0.48867 time load: 0.05472 time model: 0.32118
[epoch: 9, batch:   1700] loss: 0.54592 time load: 0.06876 time model: 0.31817
[epoch: 9, batch:   1800] loss: 0.40072 time load: 0.05304 time model: 0.31456
[epoch: 9, batch:   1900] loss: 0.51874 time load: 0.05428 time model: 0.31544
[epoch: 9, batch:   2000] loss: 0.49184 time load: 0.10950 time model: 0.32089
[epoch: 9, batch:   2100] loss: 0.59270 time load: 0.05685 time model: 0.32307
[epoch: 9, batch:   2200] loss: 0.42466 time load: 0.11800 time model: 0.31589
[epoch: 9, batch:   2300] loss: 0.52468 time load: 0.05416 time model: 0.31823
[epoch: 9, batch:   2400] loss: 0.56507 time load: 0.10751 time model: 0.32150
[epoch: 9, batch:   2500] loss: 0.46917 time load: 0.05610 time model: 0.31708
[epoch: 9, batch:   2600] loss: 0.53797 time load: 0.10803 time model: 0.32166
[epoch: 9, batch:   2700] loss: 0.44391 time load: 0.05841 time model: 0.33031
[epoch: 9, batch:   2800] loss: 0.44124 time load: 0.10739 time model: 0.32065
[epoch: 9, batch:   2900] loss: 0.46306 time load: 0.05599 time model: 0.32274
[epoch: 9, batch:   3000] loss: 0.44783 time load: 0.11050 time model: 0.31980
[epoch: 9, batch:   3100] loss: 0.47553 time load: 0.05559 time model: 0.32250
[epoch: 9, batch:   3200] loss: 0.59481 time load: 0.10971 time model: 0.32306
[epoch: 9, batch:   3300] loss: 0.60985 time load: 0.05376 time model: 0.31911
[epoch: 9, batch:   3400] loss: 0.53001 time load: 0.11578 time model: 0.32325
[epoch: 9, batch:   3500] loss: 0.56043 time load: 0.05708 time model: 0.32272
[epoch: 9, batch:   3600] loss: 0.54196 time load: 0.11051 time model: 0.31516
[epoch: 9, batch:   3700] loss: 0.44890 time load: 0.05231 time model: 0.31612
[epoch: 9, batch:   3800] loss: 0.58909 time load: 0.11261 time model: 0.32154
[epoch: 9, batch:   3900] loss: 0.53856 time load: 0.05775 time model: 0.31985
[epoch: 9, batch:   4000] loss: 0.46549 time load: 0.10800 time model: 0.32079
[epoch: 9, batch:   4100] loss: 0.57846 time load: 0.05672 time model: 0.32021
[epoch: 9, batch:   4200] loss: 0.64552 time load: 0.10715 time model: 0.31964
[epoch: 9, batch:   4300] loss: 0.59014 time load: 0.05761 time model: 0.32656
[epoch: 9, batch:   4400] loss: 0.65326 time load: 0.11851 time model: 0.31642
[epoch: 9, batch:   4500] loss: 0.59178 time load: 0.05693 time model: 0.32289
[epoch: 9, batch:   4600] loss: 0.75648 time load: 0.10393 time model: 0.31049
[epoch: 9, batch:   4700] loss: 0.55120 time load: 0.05316 time model: 0.31187
[epoch: 9, batch:   4800] loss: 0.45788 time load: 0.10617 time model: 0.32134
[epoch: 9, batch:   4900] loss: 0.55275 time load: 0.05772 time model: 0.31213
[epoch: 9, batch:   5000] loss: 0.51650 time load: 0.12307 time model: 0.31905
Epoch: 9/100 Loss: 0.5410820285933791 Train MSESteer: 2259.979 Train MSESpeed: 7.452 MSESteer: 850.379 MSESpeed: 7.993
[epoch: 10, batch:    100] loss: 0.37922 time load: 0.05431 time model: 0.32435
[epoch: 10, batch:    200] loss: 0.52864 time load: 0.06609 time model: 0.31862
[epoch: 10, batch:    300] loss: 0.69636 time load: 0.05617 time model: 0.31623
[epoch: 10, batch:    400] loss: 0.62674 time load: 0.06388 time model: 0.31550
[epoch: 10, batch:    500] loss: 0.59774 time load: 0.05656 time model: 0.32210
[epoch: 10, batch:    600] loss: 0.49501 time load: 0.06701 time model: 0.32069
[epoch: 10, batch:    700] loss: 0.38024 time load: 0.05705 time model: 0.32195
[epoch: 10, batch:    800] loss: 0.59590 time load: 0.06194 time model: 0.31198
[epoch: 10, batch:    900] loss: 0.40533 time load: 0.05588 time model: 0.31690
[epoch: 10, batch:   1000] loss: 0.39833 time load: 0.06182 time model: 0.32265
[epoch: 10, batch:   1100] loss: 0.67513 time load: 0.06706 time model: 0.32217
[epoch: 10, batch:   1200] loss: 0.40688 time load: 0.06517 time model: 0.32110
[epoch: 10, batch:   1300] loss: 0.56831 time load: 0.06450 time model: 0.32111
[epoch: 10, batch:   1400] loss: 0.52672 time load: 0.06509 time model: 0.31494
[epoch: 10, batch:   1500] loss: 0.53817 time load: 0.06999 time model: 0.32209
[epoch: 10, batch:   1600] loss: 0.50824 time load: 0.06665 time model: 0.32195
[epoch: 10, batch:   1700] loss: 0.43637 time load: 0.06473 time model: 0.32732
[epoch: 10, batch:   1800] loss: 0.57072 time load: 0.07058 time model: 0.31637
[epoch: 10, batch:   1900] loss: 0.48054 time load: 0.06551 time model: 0.31628
[epoch: 10, batch:   2000] loss: 0.56049 time load: 0.06565 time model: 0.31757
[epoch: 10, batch:   2100] loss: 0.53252 time load: 0.06347 time model: 0.32695
[epoch: 10, batch:   2200] loss: 0.64552 time load: 0.06163 time model: 0.32142
[epoch: 10, batch:   2300] loss: 0.51655 time load: 0.06703 time model: 0.31833
[epoch: 10, batch:   2400] loss: 0.48669 time load: 0.06501 time model: 0.32438
[epoch: 10, batch:   2500] loss: 0.60982 time load: 0.06515 time model: 0.31885
[epoch: 10, batch:   2600] loss: 0.53925 time load: 0.06815 time model: 0.31913
[epoch: 10, batch:   2700] loss: 0.55097 time load: 0.06795 time model: 0.32145
[epoch: 10, batch:   2800] loss: 0.54109 time load: 0.06686 time model: 0.31893
[epoch: 10, batch:   2900] loss: 0.55597 time load: 0.06410 time model: 0.32425
[epoch: 10, batch:   3000] loss: 0.45035 time load: 0.06412 time model: 0.31958
[epoch: 10, batch:   3100] loss: 0.52228 time load: 0.06360 time model: 0.31348
[epoch: 10, batch:   3200] loss: 0.54932 time load: 0.07755 time model: 0.32019
[epoch: 10, batch:   3300] loss: 0.55131 time load: 0.06445 time model: 0.32744
[epoch: 10, batch:   3400] loss: 0.60488 time load: 0.06693 time model: 0.33023
[epoch: 10, batch:   3500] loss: 0.46990 time load: 0.06602 time model: 0.32718
[epoch: 10, batch:   3600] loss: 0.52577 time load: 0.06232 time model: 0.31292
[epoch: 10, batch:   3700] loss: 0.50585 time load: 0.06715 time model: 0.32720
[epoch: 10, batch:   3800] loss: 0.41894 time load: 0.06932 time model: 0.32301
[epoch: 10, batch:   3900] loss: 0.47768 time load: 0.06734 time model: 0.32112
[epoch: 10, batch:   4000] loss: 0.45948 time load: 0.06570 time model: 0.32620
[epoch: 10, batch:   4100] loss: 0.48138 time load: 0.06654 time model: 0.32363
[epoch: 10, batch:   4200] loss: 0.44585 time load: 0.06348 time model: 0.32773
[epoch: 10, batch:   4300] loss: 0.56812 time load: 0.06569 time model: 0.32662
[epoch: 10, batch:   4400] loss: 0.42342 time load: 0.06551 time model: 0.31799
[epoch: 10, batch:   4500] loss: 0.42338 time load: 0.06613 time model: 0.31879
[epoch: 10, batch:   4600] loss: 0.38533 time load: 0.06330 time model: 0.32238
[epoch: 10, batch:   4700] loss: 0.51846 time load: 0.06638 time model: 0.31979
[epoch: 10, batch:   4800] loss: 0.51825 time load: 0.06812 time model: 0.31871
[epoch: 10, batch:   4900] loss: 0.48054 time load: 0.06422 time model: 0.32296
[epoch: 10, batch:   5000] loss: 0.45269 time load: 0.06744 time model: 0.32278
Epoch: 10/100 Loss: 0.5112179481153397 Train MSESteer: 2122.163 Train MSESpeed: 7.188 MSESteer: 1099.207 MSESpeed: 8.205
[epoch: 11, batch:    100] loss: 0.51576 time load: 0.05393 time model: 0.32109
[epoch: 11, batch:    200] loss: 0.53936 time load: 0.06661 time model: 0.32259
[epoch: 11, batch:    300] loss: 0.52232 time load: 0.05837 time model: 0.32365
[epoch: 11, batch:    400] loss: 0.43405 time load: 0.07295 time model: 0.32228
[epoch: 11, batch:    500] loss: 0.51629 time load: 0.06133 time model: 0.32549
[epoch: 11, batch:    600] loss: 0.36534 time load: 0.06772 time model: 0.31812
[epoch: 11, batch:    700] loss: 0.54299 time load: 0.05567 time model: 0.32135
[epoch: 11, batch:    800] loss: 0.59488 time load: 0.06857 time model: 0.32438
[epoch: 11, batch:    900] loss: 0.45428 time load: 0.05538 time model: 0.32125
[epoch: 11, batch:   1000] loss: 0.44550 time load: 0.06740 time model: 0.31730
[epoch: 11, batch:   1100] loss: 0.50770 time load: 0.05636 time model: 0.32431
[epoch: 11, batch:   1200] loss: 0.55378 time load: 0.06746 time model: 0.32160
[epoch: 11, batch:   1300] loss: 0.57578 time load: 0.05290 time model: 0.32002
[epoch: 11, batch:   1400] loss: 0.49494 time load: 0.06964 time model: 0.32286
[epoch: 11, batch:   1500] loss: 0.53304 time load: 0.05545 time model: 0.31844
[epoch: 11, batch:   1600] loss: 0.38698 time load: 0.07879 time model: 0.31898
[epoch: 11, batch:   1700] loss: 0.48336 time load: 0.05389 time model: 0.32199
[epoch: 11, batch:   1800] loss: 0.55685 time load: 0.07102 time model: 0.31862
[epoch: 11, batch:   1900] loss: 0.46931 time load: 0.06526 time model: 0.32142
[epoch: 11, batch:   2000] loss: 0.49593 time load: 0.06652 time model: 0.31963
[epoch: 11, batch:   2100] loss: 0.39870 time load: 0.05734 time model: 0.32070
[epoch: 11, batch:   2200] loss: 0.45136 time load: 0.07034 time model: 0.32917
[epoch: 11, batch:   2300] loss: 0.40317 time load: 0.05275 time model: 0.31186
[epoch: 11, batch:   2400] loss: 0.51245 time load: 0.06586 time model: 0.31622
[epoch: 11, batch:   2500] loss: 0.47195 time load: 0.05570 time model: 0.31551
[epoch: 11, batch:   2600] loss: 0.43806 time load: 0.07243 time model: 0.32054
[epoch: 11, batch:   2700] loss: 0.38065 time load: 0.05791 time model: 0.31560
[epoch: 11, batch:   2800] loss: 0.42741 time load: 0.06792 time model: 0.31179
[epoch: 11, batch:   2900] loss: 0.52125 time load: 0.05657 time model: 0.31778
[epoch: 11, batch:   3000] loss: 0.48287 time load: 0.06738 time model: 0.31648
[epoch: 11, batch:   3100] loss: 0.36941 time load: 0.05655 time model: 0.31947
[epoch: 11, batch:   3200] loss: 0.53153 time load: 0.06654 time model: 0.32236
[epoch: 11, batch:   3300] loss: 0.58274 time load: 0.05695 time model: 0.31481
[epoch: 11, batch:   3400] loss: 0.62036 time load: 0.06723 time model: 0.31886
[epoch: 11, batch:   3500] loss: 0.43766 time load: 0.05779 time model: 0.32572
[epoch: 11, batch:   3600] loss: 0.41703 time load: 0.05912 time model: 0.31750
[epoch: 11, batch:   3700] loss: 0.40755 time load: 0.05591 time model: 0.32048
[epoch: 11, batch:   3800] loss: 0.53207 time load: 0.05874 time model: 0.31831
[epoch: 11, batch:   3900] loss: 0.37858 time load: 0.05361 time model: 0.31526
[epoch: 11, batch:   4000] loss: 0.44075 time load: 0.05664 time model: 0.31671
[epoch: 11, batch:   4100] loss: 0.43107 time load: 0.05361 time model: 0.31048
[epoch: 11, batch:   4200] loss: 0.60238 time load: 0.05878 time model: 0.32018
[epoch: 11, batch:   4300] loss: 0.51811 time load: 0.05452 time model: 0.31843
[epoch: 11, batch:   4400] loss: 0.57061 time load: 0.06995 time model: 0.31326
[epoch: 11, batch:   4500] loss: 0.62707 time load: 0.05684 time model: 0.32094
[epoch: 11, batch:   4600] loss: 0.49420 time load: 0.06787 time model: 0.32204
[epoch: 11, batch:   4700] loss: 0.60292 time load: 0.05626 time model: 0.31646
[epoch: 11, batch:   4800] loss: 0.47082 time load: 0.06579 time model: 0.32185
[epoch: 11, batch:   4900] loss: 0.55851 time load: 0.05622 time model: 0.32245
[epoch: 11, batch:   5000] loss: 0.66965 time load: 0.06771 time model: 0.31872
Epoch: 11/100 Loss: 0.49446020017900544 Train MSESteer: 2059.899 Train MSESpeed: 6.866 MSESteer: 923.634 MSESpeed: 7.341
[epoch: 12, batch:    100] loss: 0.50150 time load: 0.05602 time model: 0.32334
[epoch: 12, batch:    200] loss: 0.38855 time load: 0.05902 time model: 0.32210
[epoch: 12, batch:    300] loss: 0.45426 time load: 0.10974 time model: 0.32917
[epoch: 12, batch:    400] loss: 0.37936 time load: 0.05617 time model: 0.32160
[epoch: 12, batch:    500] loss: 0.55087 time load: 0.11726 time model: 0.32016
[epoch: 12, batch:    600] loss: 0.41916 time load: 0.05753 time model: 0.31824
[epoch: 12, batch:    700] loss: 0.35668 time load: 0.10862 time model: 0.32779
[epoch: 12, batch:    800] loss: 0.40311 time load: 0.05911 time model: 0.31644
[epoch: 12, batch:    900] loss: 0.44006 time load: 0.11317 time model: 0.32015
[epoch: 12, batch:   1000] loss: 0.44261 time load: 0.05947 time model: 0.31930
[epoch: 12, batch:   1100] loss: 0.46801 time load: 0.11435 time model: 0.32453
[epoch: 12, batch:   1200] loss: 0.40002 time load: 0.05849 time model: 0.32589
[epoch: 12, batch:   1300] loss: 0.54540 time load: 0.10684 time model: 0.31824
[epoch: 12, batch:   1400] loss: 0.41693 time load: 0.05893 time model: 0.31892
[epoch: 12, batch:   1500] loss: 0.45789 time load: 0.11570 time model: 0.31747
[epoch: 12, batch:   1600] loss: 0.43625 time load: 0.05907 time model: 0.31972
[epoch: 12, batch:   1700] loss: 0.41769 time load: 0.11297 time model: 0.32088
[epoch: 12, batch:   1800] loss: 0.41001 time load: 0.05841 time model: 0.31790
[epoch: 12, batch:   1900] loss: 0.44702 time load: 0.06490 time model: 0.31607
[epoch: 12, batch:   2000] loss: 0.46561 time load: 0.05929 time model: 0.31666
[epoch: 12, batch:   2100] loss: 0.49224 time load: 0.06346 time model: 0.31867
[epoch: 12, batch:   2200] loss: 0.51464 time load: 0.05742 time model: 0.32150
[epoch: 12, batch:   2300] loss: 0.49972 time load: 0.06272 time model: 0.32178
[epoch: 12, batch:   2400] loss: 0.50830 time load: 0.05750 time model: 0.31853
[epoch: 12, batch:   2500] loss: 0.44926 time load: 0.06835 time model: 0.31713
[epoch: 12, batch:   2600] loss: 0.49075 time load: 0.05910 time model: 0.31944
[epoch: 12, batch:   2700] loss: 0.70676 time load: 0.06573 time model: 0.32649
[epoch: 12, batch:   2800] loss: 0.44110 time load: 0.06110 time model: 0.33613
[epoch: 12, batch:   2900] loss: 0.47019 time load: 0.07462 time model: 0.32141
[epoch: 12, batch:   3000] loss: 0.60083 time load: 0.05867 time model: 0.31928
[epoch: 12, batch:   3100] loss: 0.36979 time load: 0.06214 time model: 0.32872
[epoch: 12, batch:   3200] loss: 0.41179 time load: 0.06588 time model: 0.32501
[epoch: 12, batch:   3300] loss: 0.52141 time load: 0.06590 time model: 0.31732
[epoch: 12, batch:   3400] loss: 0.47361 time load: 0.05797 time model: 0.31688
[epoch: 12, batch:   3500] loss: 0.54662 time load: 0.06767 time model: 0.32507
[epoch: 12, batch:   3600] loss: 0.51769 time load: 0.05969 time model: 0.32178
[epoch: 12, batch:   3700] loss: 0.47765 time load: 0.06184 time model: 0.32232
[epoch: 12, batch:   3800] loss: 0.53955 time load: 0.05832 time model: 0.32072
[epoch: 12, batch:   3900] loss: 0.44425 time load: 0.06382 time model: 0.32406
[epoch: 12, batch:   4000] loss: 0.40684 time load: 0.05772 time model: 0.32111
[epoch: 12, batch:   4100] loss: 0.42031 time load: 0.06677 time model: 0.31693
[epoch: 12, batch:   4200] loss: 0.39714 time load: 0.06176 time model: 0.32238
[epoch: 12, batch:   4300] loss: 0.45069 time load: 0.06444 time model: 0.32369
[epoch: 12, batch:   4400] loss: 0.46978 time load: 0.05843 time model: 0.32032
[epoch: 12, batch:   4500] loss: 0.36678 time load: 0.06242 time model: 0.32411
[epoch: 12, batch:   4600] loss: 0.45403 time load: 0.05767 time model: 0.32361
[epoch: 12, batch:   4700] loss: 0.52048 time load: 0.06671 time model: 0.33370
[epoch: 12, batch:   4800] loss: 0.45978 time load: 0.05703 time model: 0.32114
[epoch: 12, batch:   4900] loss: 0.47284 time load: 0.06314 time model: 0.32054
[epoch: 12, batch:   5000] loss: 0.36853 time load: 0.05812 time model: 0.31909
Epoch: 12/100 Loss: 0.4610009747584237 Train MSESteer: 1897.383 Train MSESpeed: 6.668 MSESteer: 826.997 MSESpeed: 8.235
[epoch: 13, batch:    100] loss: 0.56629 time load: 0.05496 time model: 0.31810
[epoch: 13, batch:    200] loss: 0.57398 time load: 0.06578 time model: 0.31662
[epoch: 13, batch:    300] loss: 0.41356 time load: 0.05421 time model: 0.32021
[epoch: 13, batch:    400] loss: 0.37656 time load: 0.06370 time model: 0.32035
[epoch: 13, batch:    500] loss: 0.36393 time load: 0.05635 time model: 0.31985
[epoch: 13, batch:    600] loss: 0.45381 time load: 0.06754 time model: 0.32082
[epoch: 13, batch:    700] loss: 0.45622 time load: 0.05431 time model: 0.31736
[epoch: 13, batch:    800] loss: 0.39481 time load: 0.06253 time model: 0.32510
[epoch: 13, batch:    900] loss: 0.44457 time load: 0.05444 time model: 0.32050
[epoch: 13, batch:   1000] loss: 0.44426 time load: 0.06634 time model: 0.32814
[epoch: 13, batch:   1100] loss: 0.51324 time load: 0.05379 time model: 0.32184
[epoch: 13, batch:   1200] loss: 0.51960 time load: 0.06446 time model: 0.32441
[epoch: 13, batch:   1300] loss: 0.42590 time load: 0.05493 time model: 0.31960
[epoch: 13, batch:   1400] loss: 0.43733 time load: 0.06415 time model: 0.32680
[epoch: 13, batch:   1500] loss: 0.42935 time load: 0.06093 time model: 0.32016
[epoch: 13, batch:   1600] loss: 0.42278 time load: 0.07801 time model: 0.32010
[epoch: 13, batch:   1700] loss: 0.39033 time load: 0.06809 time model: 0.31641
[epoch: 13, batch:   1800] loss: 0.46027 time load: 0.06928 time model: 0.31648
[epoch: 13, batch:   1900] loss: 0.58490 time load: 0.06383 time model: 0.31732
[epoch: 13, batch:   2000] loss: 0.39959 time load: 0.06523 time model: 0.33401
[epoch: 13, batch:   2100] loss: 0.49277 time load: 0.06458 time model: 0.31939
[epoch: 13, batch:   2200] loss: 0.51872 time load: 0.06878 time model: 0.32269
[epoch: 13, batch:   2300] loss: 0.40557 time load: 0.06410 time model: 0.33304
[epoch: 13, batch:   2400] loss: 0.39755 time load: 0.06450 time model: 0.31111
[epoch: 13, batch:   2500] loss: 0.55421 time load: 0.06183 time model: 0.32087
[epoch: 13, batch:   2600] loss: 0.36625 time load: 0.06371 time model: 0.31691
[epoch: 13, batch:   2700] loss: 0.47577 time load: 0.06133 time model: 0.31725
[epoch: 13, batch:   2800] loss: 0.49151 time load: 0.06318 time model: 0.31009
[epoch: 13, batch:   2900] loss: 0.50383 time load: 0.05952 time model: 0.31209
[epoch: 13, batch:   3000] loss: 0.51377 time load: 0.06321 time model: 0.31573
[epoch: 13, batch:   3100] loss: 0.46152 time load: 0.06590 time model: 0.32752
[epoch: 13, batch:   3200] loss: 0.42006 time load: 0.06355 time model: 0.32662
[epoch: 13, batch:   3300] loss: 0.36338 time load: 0.06553 time model: 0.31199
[epoch: 13, batch:   3400] loss: 0.46670 time load: 0.06531 time model: 0.32084
[epoch: 13, batch:   3500] loss: 0.39825 time load: 0.06449 time model: 0.32077
[epoch: 13, batch:   3600] loss: 0.40825 time load: 0.06593 time model: 0.32257
[epoch: 13, batch:   3700] loss: 0.36003 time load: 0.06370 time model: 0.31133
[epoch: 13, batch:   3800] loss: 0.37511 time load: 0.06511 time model: 0.31426
[epoch: 13, batch:   3900] loss: 0.45117 time load: 0.07301 time model: 0.31979
[epoch: 13, batch:   4000] loss: 0.45223 time load: 0.06759 time model: 0.31548
[epoch: 13, batch:   4100] loss: 0.43137 time load: 0.06365 time model: 0.32433
[epoch: 13, batch:   4200] loss: 0.35378 time load: 0.06321 time model: 0.31879
[epoch: 13, batch:   4300] loss: 0.45835 time load: 0.06205 time model: 0.31708
[epoch: 13, batch:   4400] loss: 0.39514 time load: 0.07013 time model: 0.30969
[epoch: 13, batch:   4500] loss: 0.42228 time load: 0.06153 time model: 0.31092
[epoch: 13, batch:   4600] loss: 0.50056 time load: 0.06394 time model: 0.31467
[epoch: 13, batch:   4700] loss: 0.52320 time load: 0.07197 time model: 0.31816
[epoch: 13, batch:   4800] loss: 0.41289 time load: 0.06667 time model: 0.32334
[epoch: 13, batch:   4900] loss: 0.44715 time load: 0.06212 time model: 0.32245
[epoch: 13, batch:   5000] loss: 0.42659 time load: 0.06789 time model: 0.32350
Epoch: 13/100 Loss: 0.4465151427354863 Train MSESteer: 1838.459 Train MSESpeed: 6.452 MSESteer: 684.027 MSESpeed: 8.433
[epoch: 14, batch:    100] loss: 0.32607 time load: 0.05793 time model: 0.32225
[epoch: 14, batch:    200] loss: 0.37199 time load: 0.06402 time model: 0.32302
[epoch: 14, batch:    300] loss: 0.39423 time load: 0.05505 time model: 0.32013
[epoch: 14, batch:    400] loss: 0.52376 time load: 0.06361 time model: 0.32383
[epoch: 14, batch:    500] loss: 0.43497 time load: 0.05568 time model: 0.31870
[epoch: 14, batch:    600] loss: 0.43021 time load: 0.06395 time model: 0.32939
[epoch: 14, batch:    700] loss: 0.34956 time load: 0.05551 time model: 0.31423
[epoch: 14, batch:    800] loss: 0.37089 time load: 0.06662 time model: 0.31436
[epoch: 14, batch:    900] loss: 0.42881 time load: 0.05699 time model: 0.32348
[epoch: 14, batch:   1000] loss: 0.38314 time load: 0.06487 time model: 0.32201
[epoch: 14, batch:   1100] loss: 0.40084 time load: 0.05702 time model: 0.31534
[epoch: 14, batch:   1200] loss: 0.32308 time load: 0.06610 time model: 0.32132
[epoch: 14, batch:   1300] loss: 0.44166 time load: 0.05490 time model: 0.31397
[epoch: 14, batch:   1400] loss: 0.36146 time load: 0.06566 time model: 0.32314
[epoch: 14, batch:   1500] loss: 0.44303 time load: 0.05424 time model: 0.31820
[epoch: 14, batch:   1600] loss: 0.43177 time load: 0.06419 time model: 0.31525
[epoch: 14, batch:   1700] loss: 0.36296 time load: 0.05760 time model: 0.32265
[epoch: 14, batch:   1800] loss: 0.39911 time load: 0.06610 time model: 0.32303
[epoch: 14, batch:   1900] loss: 0.54929 time load: 0.05855 time model: 0.32393
[epoch: 14, batch:   2000] loss: 0.42803 time load: 0.06609 time model: 0.31841
[epoch: 14, batch:   2100] loss: 0.41778 time load: 0.05779 time model: 0.32274
[epoch: 14, batch:   2200] loss: 0.37588 time load: 0.06801 time model: 0.32464
[epoch: 14, batch:   2300] loss: 0.39543 time load: 0.05626 time model: 0.31781
[epoch: 14, batch:   2400] loss: 0.45144 time load: 0.06868 time model: 0.32416
[epoch: 14, batch:   2500] loss: 0.42806 time load: 0.05816 time model: 0.32209
[epoch: 14, batch:   2600] loss: 0.50842 time load: 0.06785 time model: 0.32106
[epoch: 14, batch:   2700] loss: 0.34732 time load: 0.05672 time model: 0.32859
[epoch: 14, batch:   2800] loss: 0.36611 time load: 0.06186 time model: 0.31030
[epoch: 14, batch:   2900] loss: 0.38613 time load: 0.05815 time model: 0.31713
[epoch: 14, batch:   3000] loss: 0.43002 time load: 0.06782 time model: 0.32093
[epoch: 14, batch:   3100] loss: 0.42655 time load: 0.05736 time model: 0.32082
[epoch: 14, batch:   3200] loss: 0.54049 time load: 0.06692 time model: 0.32408
[epoch: 14, batch:   3300] loss: 0.56587 time load: 0.05596 time model: 0.31630
[epoch: 14, batch:   3400] loss: 0.44888 time load: 0.06690 time model: 0.32467
[epoch: 14, batch:   3500] loss: 0.43786 time load: 0.05768 time model: 0.31984
[epoch: 14, batch:   3600] loss: 0.49245 time load: 0.06531 time model: 0.32066
[epoch: 14, batch:   3700] loss: 0.40474 time load: 0.05722 time model: 0.31847
[epoch: 14, batch:   3800] loss: 0.50331 time load: 0.06176 time model: 0.31680
[epoch: 14, batch:   3900] loss: 0.41539 time load: 0.05762 time model: 0.31665
[epoch: 14, batch:   4000] loss: 0.50764 time load: 0.06824 time model: 0.30831
[epoch: 14, batch:   4100] loss: 0.44015 time load: 0.05474 time model: 0.31313
[epoch: 14, batch:   4200] loss: 0.40405 time load: 0.06432 time model: 0.32206
[epoch: 14, batch:   4300] loss: 0.52619 time load: 0.05983 time model: 0.32613
[epoch: 14, batch:   4400] loss: 0.51686 time load: 0.06707 time model: 0.32326
[epoch: 14, batch:   4500] loss: 0.39043 time load: 0.05613 time model: 0.31638
[epoch: 14, batch:   4600] loss: 0.44908 time load: 0.06254 time model: 0.33195
[epoch: 14, batch:   4700] loss: 0.44392 time load: 0.05702 time model: 0.32231
[epoch: 14, batch:   4800] loss: 0.55349 time load: 0.06438 time model: 0.32707
[epoch: 14, batch:   4900] loss: 0.55716 time load: 0.05565 time model: 0.32138
[epoch: 14, batch:   5000] loss: 0.61248 time load: 0.06527 time model: 0.32420
Epoch: 14/100 Loss: 0.43824265107031696 Train MSESteer: 1802.444 Train MSESpeed: 6.35 MSESteer: 771.294 MSESpeed: 8.603
[epoch: 15, batch:    100] loss: 0.45734 time load: 0.06209 time model: 0.32120
[epoch: 15, batch:    200] loss: 0.34111 time load: 0.06822 time model: 0.32350
[epoch: 15, batch:    300] loss: 0.44900 time load: 0.06636 time model: 0.31921
[epoch: 15, batch:    400] loss: 0.33485 time load: 0.06208 time model: 0.32688
[epoch: 15, batch:    500] loss: 0.40955 time load: 0.06955 time model: 0.32202
[epoch: 15, batch:    600] loss: 0.41058 time load: 0.07315 time model: 0.32076
[epoch: 15, batch:    700] loss: 0.42732 time load: 0.06286 time model: 0.32335
[epoch: 15, batch:    800] loss: 0.46710 time load: 0.07017 time model: 0.32514
[epoch: 15, batch:    900] loss: 0.34520 time load: 0.06716 time model: 0.31678
[epoch: 15, batch:   1000] loss: 0.42783 time load: 0.06633 time model: 0.32302
[epoch: 15, batch:   1100] loss: 0.34650 time load: 0.06382 time model: 0.31712
[epoch: 15, batch:   1200] loss: 0.41017 time load: 0.06655 time model: 0.31971
[epoch: 15, batch:   1300] loss: 0.37291 time load: 0.06235 time model: 0.32276
[epoch: 15, batch:   1400] loss: 0.41333 time load: 0.06456 time model: 0.32226
[epoch: 15, batch:   1500] loss: 0.38199 time load: 0.06410 time model: 0.32083
[epoch: 15, batch:   1600] loss: 0.62777 time load: 0.06146 time model: 0.32032
[epoch: 15, batch:   1700] loss: 0.45301 time load: 0.06740 time model: 0.31872
[epoch: 15, batch:   1800] loss: 0.48941 time load: 0.06481 time model: 0.32278
[epoch: 15, batch:   1900] loss: 0.43000 time load: 0.06457 time model: 0.32057
[epoch: 15, batch:   2000] loss: 0.38028 time load: 0.06795 time model: 0.32175
[epoch: 15, batch:   2100] loss: 0.47800 time load: 0.06656 time model: 0.31696
[epoch: 15, batch:   2200] loss: 0.34848 time load: 0.06382 time model: 0.31478
[epoch: 15, batch:   2300] loss: 0.39279 time load: 0.06673 time model: 0.31972
[epoch: 15, batch:   2400] loss: 0.37382 time load: 0.06872 time model: 0.31747
[epoch: 15, batch:   2500] loss: 0.58219 time load: 0.06539 time model: 0.32201
[epoch: 15, batch:   2600] loss: 0.44485 time load: 0.06644 time model: 0.32190
[epoch: 15, batch:   2700] loss: 0.42372 time load: 0.06709 time model: 0.33997
[epoch: 15, batch:   2800] loss: 0.34356 time load: 0.06764 time model: 0.32000
[epoch: 15, batch:   2900] loss: 0.42866 time load: 0.06431 time model: 0.32152
[epoch: 15, batch:   3000] loss: 0.38024 time load: 0.06631 time model: 0.31837
[epoch: 15, batch:   3100] loss: 0.44776 time load: 0.06544 time model: 0.32114
[epoch: 15, batch:   3200] loss: 0.44264 time load: 0.06452 time model: 0.32169
[epoch: 15, batch:   3300] loss: 0.38538 time load: 0.06981 time model: 0.32172
[epoch: 15, batch:   3400] loss: 0.37629 time load: 0.06406 time model: 0.32348
[epoch: 15, batch:   3500] loss: 0.37261 time load: 0.07815 time model: 0.31711
[epoch: 15, batch:   3600] loss: 0.38846 time load: 0.06461 time model: 0.32354
[epoch: 15, batch:   3700] loss: 0.36612 time load: 0.06515 time model: 0.31921
[epoch: 15, batch:   3800] loss: 0.40803 time load: 0.06634 time model: 0.32345
[epoch: 15, batch:   3900] loss: 0.31184 time load: 0.06372 time model: 0.31620
[epoch: 15, batch:   4000] loss: 0.40435 time load: 0.06451 time model: 0.31955
[epoch: 15, batch:   4100] loss: 0.43922 time load: 0.06390 time model: 0.32462
[epoch: 15, batch:   4200] loss: 0.40932 time load: 0.06617 time model: 0.32134
[epoch: 15, batch:   4300] loss: 0.34002 time load: 0.06623 time model: 0.31501
[epoch: 15, batch:   4400] loss: 0.42128 time load: 0.06762 time model: 0.31946
[epoch: 15, batch:   4500] loss: 0.42791 time load: 0.06280 time model: 0.31605
[epoch: 15, batch:   4600] loss: 0.34717 time load: 0.07403 time model: 0.31326
[epoch: 15, batch:   4700] loss: 0.46577 time load: 0.06392 time model: 0.32165
[epoch: 15, batch:   4800] loss: 0.41194 time load: 0.06827 time model: 0.32197
[epoch: 15, batch:   4900] loss: 0.49623 time load: 0.06890 time model: 0.32202
[epoch: 15, batch:   5000] loss: 0.41012 time load: 0.07146 time model: 0.31825
Epoch: 15/100 Loss: 0.41249270225750617 Train MSESteer: 1677.444 Train MSESpeed: 6.197 MSESteer: 869.376 MSESpeed: 7.658
[epoch: 16, batch:    100] loss: 0.39072 time load: 0.06808 time model: 0.32684
[epoch: 16, batch:    200] loss: 0.44822 time load: 0.06562 time model: 0.31677
[epoch: 16, batch:    300] loss: 0.38716 time load: 0.06370 time model: 0.31458
[epoch: 16, batch:    400] loss: 0.44006 time load: 0.06486 time model: 0.32327
[epoch: 16, batch:    500] loss: 0.38875 time load: 0.06657 time model: 0.31582
[epoch: 16, batch:    600] loss: 0.49674 time load: 0.07338 time model: 0.32082
[epoch: 16, batch:    700] loss: 0.34941 time load: 0.06326 time model: 0.31684
[epoch: 16, batch:    800] loss: 0.39538 time load: 0.07954 time model: 0.32849
[epoch: 16, batch:    900] loss: 0.30881 time load: 0.07140 time model: 0.32382
[epoch: 16, batch:   1000] loss: 0.46641 time load: 0.06438 time model: 0.32120
[epoch: 16, batch:   1100] loss: 0.51112 time load: 0.07062 time model: 0.32056
[epoch: 16, batch:   1200] loss: 0.40048 time load: 0.06463 time model: 0.31862
[epoch: 16, batch:   1300] loss: 0.42372 time load: 0.06358 time model: 0.32471
[epoch: 16, batch:   1400] loss: 0.36455 time load: 0.06633 time model: 0.31764
[epoch: 16, batch:   1500] loss: 0.37382 time load: 0.07130 time model: 0.31921
[epoch: 16, batch:   1600] loss: 0.33284 time load: 0.06418 time model: 0.32634
[epoch: 16, batch:   1700] loss: 0.41771 time load: 0.06773 time model: 0.31884
[epoch: 16, batch:   1800] loss: 0.38746 time load: 0.06306 time model: 0.32439
[epoch: 16, batch:   1900] loss: 0.30539 time load: 0.06436 time model: 0.32169
[epoch: 16, batch:   2000] loss: 0.44686 time load: 0.06366 time model: 0.32371
[epoch: 16, batch:   2100] loss: 0.39794 time load: 0.06868 time model: 0.32010
[epoch: 16, batch:   2200] loss: 0.31605 time load: 0.06285 time model: 0.32000
[epoch: 16, batch:   2300] loss: 0.39687 time load: 0.06746 time model: 0.31416
[epoch: 16, batch:   2400] loss: 0.35682 time load: 0.06617 time model: 0.32377
[epoch: 16, batch:   2500] loss: 0.35222 time load: 0.06769 time model: 0.32512
[epoch: 16, batch:   2600] loss: 0.35238 time load: 0.06505 time model: 0.32124
[epoch: 16, batch:   2700] loss: 0.33495 time load: 0.07129 time model: 0.31532
[epoch: 16, batch:   2800] loss: 0.35866 time load: 0.06524 time model: 0.32780
[epoch: 16, batch:   2900] loss: 0.38775 time load: 0.06850 time model: 0.32256
[epoch: 16, batch:   3000] loss: 0.44184 time load: 0.06553 time model: 0.31538
[epoch: 16, batch:   3100] loss: 0.35131 time load: 0.06588 time model: 0.31341
[epoch: 16, batch:   3200] loss: 0.37086 time load: 0.06810 time model: 0.32521
[epoch: 16, batch:   3300] loss: 0.37015 time load: 0.06553 time model: 0.32073
[epoch: 16, batch:   3400] loss: 0.41927 time load: 0.06603 time model: 0.31534
[epoch: 16, batch:   3500] loss: 0.44974 time load: 0.06165 time model: 0.31944
[epoch: 16, batch:   3600] loss: 0.38835 time load: 0.06604 time model: 0.31398
[epoch: 16, batch:   3700] loss: 0.49779 time load: 0.06667 time model: 0.32834
[epoch: 16, batch:   3800] loss: 0.42961 time load: 0.06921 time model: 0.32072
[epoch: 16, batch:   3900] loss: 0.41475 time load: 0.06560 time model: 0.32283
[epoch: 16, batch:   4000] loss: 0.43285 time load: 0.06700 time model: 0.31695
[epoch: 16, batch:   4100] loss: 0.41214 time load: 0.06187 time model: 0.32009
[epoch: 16, batch:   4200] loss: 0.43179 time load: 0.06248 time model: 0.31264
[epoch: 16, batch:   4300] loss: 0.42505 time load: 0.07135 time model: 0.32117
[epoch: 16, batch:   4400] loss: 0.58062 time load: 0.06497 time model: 0.32058
[epoch: 16, batch:   4500] loss: 0.38352 time load: 0.07390 time model: 0.32209
[epoch: 16, batch:   4600] loss: 0.32878 time load: 0.06696 time model: 0.32385
[epoch: 16, batch:   4700] loss: 0.32468 time load: 0.06656 time model: 0.33437
[epoch: 16, batch:   4800] loss: 0.36196 time load: 0.06334 time model: 0.32215
[epoch: 16, batch:   4900] loss: 0.40746 time load: 0.06550 time model: 0.31054
[epoch: 16, batch:   5000] loss: 0.35794 time load: 0.07094 time model: 0.31962
Epoch: 16/100 Loss: 0.3979086710143448 Train MSESteer: 1617.686 Train MSESpeed: 5.983 MSESteer: 937.612 MSESpeed: 7.904
[epoch: 17, batch:    100] loss: 0.32948 time load: 0.05515 time model: 0.31442
[epoch: 17, batch:    200] loss: 0.34357 time load: 0.06409 time model: 0.32001
[epoch: 17, batch:    300] loss: 0.50991 time load: 0.05461 time model: 0.32221
[epoch: 17, batch:    400] loss: 0.28681 time load: 0.06350 time model: 0.31737
[epoch: 17, batch:    500] loss: 0.34603 time load: 0.05276 time model: 0.31720
[epoch: 17, batch:    600] loss: 0.42015 time load: 0.06463 time model: 0.31384
[epoch: 17, batch:    700] loss: 0.40154 time load: 0.06586 time model: 0.31753
[epoch: 17, batch:    800] loss: 0.34775 time load: 0.06390 time model: 0.31397
[epoch: 17, batch:    900] loss: 0.37445 time load: 0.06243 time model: 0.31617
[epoch: 17, batch:   1000] loss: 0.41122 time load: 0.06654 time model: 0.32039
[epoch: 17, batch:   1100] loss: 0.43950 time load: 0.06264 time model: 0.31333
[epoch: 17, batch:   1200] loss: 0.41761 time load: 0.07238 time model: 0.31745
[epoch: 17, batch:   1300] loss: 0.35077 time load: 0.06584 time model: 0.32039
[epoch: 17, batch:   1400] loss: 0.27000 time load: 0.06879 time model: 0.32829
[epoch: 17, batch:   1500] loss: 0.40021 time load: 0.06725 time model: 0.32353
[epoch: 17, batch:   1600] loss: 0.54894 time load: 0.06685 time model: 0.31687
[epoch: 17, batch:   1700] loss: 0.35383 time load: 0.06497 time model: 0.32112
[epoch: 17, batch:   1800] loss: 0.40579 time load: 0.06561 time model: 0.31939
[epoch: 17, batch:   1900] loss: 0.44161 time load: 0.06437 time model: 0.32117
[epoch: 17, batch:   2000] loss: 0.46160 time load: 0.06487 time model: 0.32923
[epoch: 17, batch:   2100] loss: 0.47497 time load: 0.06059 time model: 0.31934
[epoch: 17, batch:   2200] loss: 0.38940 time load: 0.07186 time model: 0.31304
[epoch: 17, batch:   2300] loss: 0.30530 time load: 0.06303 time model: 0.31491
[epoch: 17, batch:   2400] loss: 0.33354 time load: 0.06136 time model: 0.31522
[epoch: 17, batch:   2500] loss: 0.38645 time load: 0.06650 time model: 0.31824
[epoch: 17, batch:   2600] loss: 0.46379 time load: 0.06219 time model: 0.32225
[epoch: 17, batch:   2700] loss: 0.46305 time load: 0.06199 time model: 0.33441
[epoch: 17, batch:   2800] loss: 0.39974 time load: 0.06309 time model: 0.31870
[epoch: 17, batch:   2900] loss: 0.32452 time load: 0.06709 time model: 0.32027
[epoch: 17, batch:   3000] loss: 0.40261 time load: 0.06296 time model: 0.31704
[epoch: 17, batch:   3100] loss: 0.45680 time load: 0.06658 time model: 0.31936
[epoch: 17, batch:   3200] loss: 0.29373 time load: 0.06700 time model: 0.31782
[epoch: 17, batch:   3300] loss: 0.38373 time load: 0.06007 time model: 0.31078
[epoch: 17, batch:   3400] loss: 0.35811 time load: 0.06700 time model: 0.31699
[epoch: 17, batch:   3500] loss: 0.38806 time load: 0.06473 time model: 0.31955
[epoch: 17, batch:   3600] loss: 0.32961 time load: 0.06350 time model: 0.32152
[epoch: 17, batch:   3700] loss: 0.46164 time load: 0.06232 time model: 0.32607
[epoch: 17, batch:   3800] loss: 0.31318 time load: 0.06488 time model: 0.31294
[epoch: 17, batch:   3900] loss: 0.44676 time load: 0.06342 time model: 0.31910
[epoch: 17, batch:   4000] loss: 0.34042 time load: 0.06695 time model: 0.31936
[epoch: 17, batch:   4100] loss: 0.39448 time load: 0.06321 time model: 0.31612
[epoch: 17, batch:   4200] loss: 0.36580 time load: 0.06605 time model: 0.32327
[epoch: 17, batch:   4300] loss: 0.34378 time load: 0.06307 time model: 0.31833
[epoch: 17, batch:   4400] loss: 0.47679 time load: 0.06264 time model: 0.31856
[epoch: 17, batch:   4500] loss: 0.35182 time load: 0.06108 time model: 0.31866
[epoch: 17, batch:   4600] loss: 0.44127 time load: 0.06175 time model: 0.32025
[epoch: 17, batch:   4700] loss: 0.31311 time load: 0.06402 time model: 0.32194
[epoch: 17, batch:   4800] loss: 0.45787 time load: 0.06646 time model: 0.32364
[epoch: 17, batch:   4900] loss: 0.42992 time load: 0.06259 time model: 0.31936
[epoch: 17, batch:   5000] loss: 0.38110 time load: 0.06522 time model: 0.32911
Epoch: 17/100 Loss: 0.39021761441042024 Train MSESteer: 1573.514 Train MSESpeed: 6.011 MSESteer: 1428.402 MSESpeed: 7.566
[epoch: 18, batch:    100] loss: 0.35939 time load: 0.06259 time model: 0.31799
[epoch: 18, batch:    200] loss: 0.38634 time load: 0.06343 time model: 0.31560
[epoch: 18, batch:    300] loss: 0.34595 time load: 0.06889 time model: 0.31770
[epoch: 18, batch:    400] loss: 0.27820 time load: 0.07111 time model: 0.32461
[epoch: 18, batch:    500] loss: 0.30130 time load: 0.06744 time model: 0.32057
[epoch: 18, batch:    600] loss: 0.59786 time load: 0.06862 time model: 0.31524
[epoch: 18, batch:    700] loss: 0.38098 time load: 0.08593 time model: 0.31511
[epoch: 18, batch:    800] loss: 0.44031 time load: 0.07422 time model: 0.31805
[epoch: 18, batch:    900] loss: 0.29689 time load: 0.06865 time model: 0.31865
[epoch: 18, batch:   1000] loss: 0.38704 time load: 0.06879 time model: 0.32590
[epoch: 18, batch:   1100] loss: 0.33755 time load: 0.07335 time model: 0.32698
[epoch: 18, batch:   1200] loss: 0.39714 time load: 0.06769 time model: 0.32471
[epoch: 18, batch:   1300] loss: 0.28644 time load: 0.06575 time model: 0.31711
[epoch: 18, batch:   1400] loss: 0.31635 time load: 0.06729 time model: 0.32547
[epoch: 18, batch:   1500] loss: 0.37481 time load: 0.06588 time model: 0.32274
[epoch: 18, batch:   1600] loss: 0.30385 time load: 0.07002 time model: 0.32180
[epoch: 18, batch:   1700] loss: 0.38810 time load: 0.06751 time model: 0.32248
[epoch: 18, batch:   1800] loss: 0.41944 time load: 0.07206 time model: 0.31970
[epoch: 18, batch:   1900] loss: 0.46534 time load: 0.07698 time model: 0.32424
[epoch: 18, batch:   2000] loss: 0.39218 time load: 0.07222 time model: 0.32444
[epoch: 18, batch:   2100] loss: 0.39913 time load: 0.06984 time model: 0.32204
[epoch: 18, batch:   2200] loss: 0.46345 time load: 0.06692 time model: 0.32226
[epoch: 18, batch:   2300] loss: 0.45970 time load: 0.06915 time model: 0.32333
[epoch: 18, batch:   2400] loss: 0.38280 time load: 0.06934 time model: 0.31658
[epoch: 18, batch:   2500] loss: 0.40658 time load: 0.06998 time model: 0.32106
[epoch: 18, batch:   2600] loss: 0.39119 time load: 0.06828 time model: 0.32532
[epoch: 18, batch:   2700] loss: 0.32400 time load: 0.06751 time model: 0.32363
[epoch: 18, batch:   2800] loss: 0.34024 time load: 0.07467 time model: 0.32119
[epoch: 18, batch:   2900] loss: 0.43591 time load: 0.06600 time model: 0.31910
[epoch: 18, batch:   3000] loss: 0.34015 time load: 0.06980 time model: 0.31819
[epoch: 18, batch:   3100] loss: 0.25817 time load: 0.06612 time model: 0.32851
[epoch: 18, batch:   3200] loss: 0.42208 time load: 0.07131 time model: 0.31542
[epoch: 18, batch:   3300] loss: 0.46426 time load: 0.06842 time model: 0.32259
[epoch: 18, batch:   3400] loss: 0.45443 time load: 0.06872 time model: 0.31485
[epoch: 18, batch:   3500] loss: 0.43676 time load: 0.06656 time model: 0.32603
[epoch: 18, batch:   3600] loss: 0.33605 time load: 0.07028 time model: 0.31752
[epoch: 18, batch:   3700] loss: 0.31506 time load: 0.07097 time model: 0.32346
[epoch: 18, batch:   3800] loss: 0.32110 time load: 0.07948 time model: 0.31215
[epoch: 18, batch:   3900] loss: 0.35695 time load: 0.06719 time model: 0.31819
[epoch: 18, batch:   4000] loss: 0.36389 time load: 0.06775 time model: 0.32269
[epoch: 18, batch:   4100] loss: 0.42626 time load: 0.06971 time model: 0.32691
[epoch: 18, batch:   4200] loss: 0.33802 time load: 0.06543 time model: 0.31795
[epoch: 18, batch:   4300] loss: 0.32694 time load: 0.06488 time model: 0.31388
[epoch: 18, batch:   4400] loss: 0.34477 time load: 0.06629 time model: 0.32375
[epoch: 18, batch:   4500] loss: 0.33702 time load: 0.06825 time model: 0.31825
[epoch: 18, batch:   4600] loss: 0.35063 time load: 0.06711 time model: 0.32651
[epoch: 18, batch:   4700] loss: 0.34084 time load: 0.07159 time model: 0.32521
[epoch: 18, batch:   4800] loss: 0.43358 time load: 0.06879 time model: 0.32188
[epoch: 18, batch:   4900] loss: 0.48713 time load: 0.06866 time model: 0.31279
[epoch: 18, batch:   5000] loss: 0.32726 time load: 0.06332 time model: 0.31229
Epoch: 18/100 Loss: 0.3772968644522215 Train MSESteer: 1511.87 Train MSESpeed: 5.924 MSESteer: 838.493 MSESpeed: 7.413
[epoch: 19, batch:    100] loss: 0.36824 time load: 0.06863 time model: 0.31768
[epoch: 19, batch:    200] loss: 0.38614 time load: 0.06330 time model: 0.31624
[epoch: 19, batch:    300] loss: 0.31186 time load: 0.06724 time model: 0.32204
[epoch: 19, batch:    400] loss: 0.38528 time load: 0.06426 time model: 0.31953
[epoch: 19, batch:    500] loss: 0.39172 time load: 0.06850 time model: 0.31459
[epoch: 19, batch:    600] loss: 0.40861 time load: 0.06568 time model: 0.31817
[epoch: 19, batch:    700] loss: 0.34858 time load: 0.06795 time model: 0.31830
[epoch: 19, batch:    800] loss: 0.35112 time load: 0.06476 time model: 0.32080
[epoch: 19, batch:    900] loss: 0.34140 time load: 0.06620 time model: 0.32003
[epoch: 19, batch:   1000] loss: 0.33212 time load: 0.06582 time model: 0.32297
[epoch: 19, batch:   1100] loss: 0.37273 time load: 0.06811 time model: 0.32868
[epoch: 19, batch:   1200] loss: 0.39085 time load: 0.06520 time model: 0.31245
[epoch: 19, batch:   1300] loss: 0.26661 time load: 0.06996 time model: 0.31724
[epoch: 19, batch:   1400] loss: 0.36385 time load: 0.07077 time model: 0.32012
[epoch: 19, batch:   1500] loss: 0.38738 time load: 0.06901 time model: 0.31488
[epoch: 19, batch:   1600] loss: 0.32568 time load: 0.06455 time model: 0.30870
[epoch: 19, batch:   1700] loss: 0.37148 time load: 0.06874 time model: 0.32182
[epoch: 19, batch:   1800] loss: 0.33987 time load: 0.06550 time model: 0.32297
[epoch: 19, batch:   1900] loss: 0.30591 time load: 0.06928 time model: 0.32067
[epoch: 19, batch:   2000] loss: 0.25880 time load: 0.06907 time model: 0.32002
[epoch: 19, batch:   2100] loss: 0.30343 time load: 0.06911 time model: 0.32579
[epoch: 19, batch:   2200] loss: 0.31770 time load: 0.05688 time model: 0.32357
[epoch: 19, batch:   2300] loss: 0.34733 time load: 0.06814 time model: 0.31615
[epoch: 19, batch:   2400] loss: 0.45784 time load: 0.05684 time model: 0.32666
[epoch: 19, batch:   2500] loss: 0.33309 time load: 0.07026 time model: 0.32800
[epoch: 19, batch:   2600] loss: 0.34038 time load: 0.05567 time model: 0.32063
[epoch: 19, batch:   2700] loss: 0.37212 time load: 0.07002 time model: 0.32258
[epoch: 19, batch:   2800] loss: 0.42232 time load: 0.05368 time model: 0.31867
[epoch: 19, batch:   2900] loss: 0.38274 time load: 0.06821 time model: 0.31896
[epoch: 19, batch:   3000] loss: 0.35120 time load: 0.05853 time model: 0.31923
[epoch: 19, batch:   3100] loss: 0.43790 time load: 0.06633 time model: 0.32137
[epoch: 19, batch:   3200] loss: 0.46318 time load: 0.05643 time model: 0.31920
[epoch: 19, batch:   3300] loss: 0.54173 time load: 0.06878 time model: 0.31859
[epoch: 19, batch:   3400] loss: 0.34519 time load: 0.05796 time model: 0.32197
[epoch: 19, batch:   3500] loss: 0.33606 time load: 0.06714 time model: 0.32175
[epoch: 19, batch:   3600] loss: 0.32714 time load: 0.05679 time model: 0.31559
[epoch: 19, batch:   3700] loss: 0.35864 time load: 0.06959 time model: 0.31671
[epoch: 19, batch:   3800] loss: 0.42628 time load: 0.05678 time model: 0.31059
[epoch: 19, batch:   3900] loss: 0.41095 time load: 0.06416 time model: 0.31667
[epoch: 19, batch:   4000] loss: 0.32300 time load: 0.05726 time model: 0.32033
[epoch: 19, batch:   4100] loss: 0.35455 time load: 0.06563 time model: 0.31771
[epoch: 19, batch:   4200] loss: 0.52891 time load: 0.05703 time model: 0.31565
[epoch: 19, batch:   4300] loss: 0.42064 time load: 0.06589 time model: 0.32880
[epoch: 19, batch:   4400] loss: 0.48101 time load: 0.05692 time model: 0.31587
[epoch: 19, batch:   4500] loss: 0.44456 time load: 0.06499 time model: 0.32379
[epoch: 19, batch:   4600] loss: 0.43150 time load: 0.05582 time model: 0.31544
[epoch: 19, batch:   4700] loss: 0.41287 time load: 0.06616 time model: 0.32092
[epoch: 19, batch:   4800] loss: 0.40318 time load: 0.05663 time model: 0.31970
[epoch: 19, batch:   4900] loss: 0.33901 time load: 0.06360 time model: 0.31903
[epoch: 19, batch:   5000] loss: 0.32510 time load: 0.05556 time model: 0.31838
Epoch: 19/100 Loss: 0.37585861759890576 Train MSESteer: 1521.229 Train MSESpeed: 5.722 MSESteer: 1807.134 MSESpeed: 7.566
[epoch: 20, batch:    100] loss: 0.49852 time load: 0.05647 time model: 0.32182
[epoch: 20, batch:    200] loss: 0.51066 time load: 0.06776 time model: 0.31616
[epoch: 20, batch:    300] loss: 0.39899 time load: 0.05648 time model: 0.31812
[epoch: 20, batch:    400] loss: 0.45842 time load: 0.06848 time model: 0.32047
[epoch: 20, batch:    500] loss: 0.39855 time load: 0.05379 time model: 0.31292
[epoch: 20, batch:    600] loss: 0.40622 time load: 0.06500 time model: 0.31708
[epoch: 20, batch:    700] loss: 0.31888 time load: 0.05901 time model: 0.32046
[epoch: 20, batch:    800] loss: 0.35234 time load: 0.06598 time model: 0.32286
[epoch: 20, batch:    900] loss: 0.43838 time load: 0.05514 time model: 0.32496
[epoch: 20, batch:   1000] loss: 0.45042 time load: 0.06720 time model: 0.32484
[epoch: 20, batch:   1100] loss: 0.32195 time load: 0.05775 time model: 0.32122
[epoch: 20, batch:   1200] loss: 0.41219 time load: 0.05760 time model: 0.31988
[epoch: 20, batch:   1300] loss: 0.39971 time load: 0.05945 time model: 0.32578
[epoch: 20, batch:   1400] loss: 0.33736 time load: 0.05600 time model: 0.32971
[epoch: 20, batch:   1500] loss: 0.32076 time load: 0.05635 time model: 0.31997
[epoch: 20, batch:   1600] loss: 0.35421 time load: 0.06437 time model: 0.31290
[epoch: 20, batch:   1700] loss: 0.42563 time load: 0.05542 time model: 0.32076
[epoch: 20, batch:   1800] loss: 0.27904 time load: 0.06507 time model: 0.31944
[epoch: 20, batch:   1900] loss: 0.41768 time load: 0.05734 time model: 0.32202
[epoch: 20, batch:   2000] loss: 0.36858 time load: 0.06575 time model: 0.31779
[epoch: 20, batch:   2100] loss: 0.35347 time load: 0.06163 time model: 0.31756
[epoch: 20, batch:   2200] loss: 0.37036 time load: 0.06587 time model: 0.32400
[epoch: 20, batch:   2300] loss: 0.41809 time load: 0.05570 time model: 0.31949
[epoch: 20, batch:   2400] loss: 0.35100 time load: 0.06777 time model: 0.31857
[epoch: 20, batch:   2500] loss: 0.26482 time load: 0.05598 time model: 0.31849
[epoch: 20, batch:   2600] loss: 0.27372 time load: 0.06353 time model: 0.32901
[epoch: 20, batch:   2700] loss: 0.41404 time load: 0.05613 time model: 0.31555
[epoch: 20, batch:   2800] loss: 0.35817 time load: 0.06467 time model: 0.31975
[epoch: 20, batch:   2900] loss: 0.34377 time load: 0.05652 time model: 0.31830
[epoch: 20, batch:   3000] loss: 0.37764 time load: 0.06467 time model: 0.32264
[epoch: 20, batch:   3100] loss: 0.35522 time load: 0.05608 time model: 0.31831
[epoch: 20, batch:   3200] loss: 0.32462 time load: 0.06565 time model: 0.32062
[epoch: 20, batch:   3300] loss: 0.31804 time load: 0.05703 time model: 0.32235
[epoch: 20, batch:   3400] loss: 0.36760 time load: 0.06213 time model: 0.31632
[epoch: 20, batch:   3500] loss: 0.31536 time load: 0.05846 time model: 0.31941
[epoch: 20, batch:   3600] loss: 0.30912 time load: 0.06007 time model: 0.31783
[epoch: 20, batch:   3700] loss: 0.34984 time load: 0.05736 time model: 0.32301
[epoch: 20, batch:   3800] loss: 0.32746 time load: 0.06672 time model: 0.32384
[epoch: 20, batch:   3900] loss: 0.36478 time load: 0.05805 time model: 0.33331
[epoch: 20, batch:   4000] loss: 0.32452 time load: 0.06877 time model: 0.32250
[epoch: 20, batch:   4100] loss: 0.40758 time load: 0.11908 time model: 0.32703
[epoch: 20, batch:   4200] loss: 0.35239 time load: 0.05616 time model: 0.31634
[epoch: 20, batch:   4300] loss: 0.33928 time load: 0.12436 time model: 0.31596
[epoch: 20, batch:   4400] loss: 0.31294 time load: 0.05573 time model: 0.32146
[epoch: 20, batch:   4500] loss: 0.31675 time load: 0.10988 time model: 0.32213
[epoch: 20, batch:   4600] loss: 0.39747 time load: 0.05476 time model: 0.32104
[epoch: 20, batch:   4700] loss: 0.35214 time load: 0.06416 time model: 0.32358
[epoch: 20, batch:   4800] loss: 0.37595 time load: 0.05620 time model: 0.32386
[epoch: 20, batch:   4900] loss: 0.31409 time load: 0.06737 time model: 0.31705
[epoch: 20, batch:   5000] loss: 0.29827 time load: 0.05560 time model: 0.31657
Epoch: 20/100 Loss: 0.3643079238871973 Train MSESteer: 1447.293 Train MSESpeed: 5.861 MSESteer: 964.483 MSESpeed: 7.711
[epoch: 21, batch:    100] loss: 0.30058 time load: 0.06603 time model: 0.32092
[epoch: 21, batch:    200] loss: 0.32689 time load: 0.06829 time model: 0.32021
[epoch: 21, batch:    300] loss: 0.35629 time load: 0.06788 time model: 0.31969
[epoch: 21, batch:    400] loss: 0.31932 time load: 0.06351 time model: 0.32473
[epoch: 21, batch:    500] loss: 0.36508 time load: 0.06573 time model: 0.31460
[epoch: 21, batch:    600] loss: 0.29542 time load: 0.06651 time model: 0.32374
[epoch: 21, batch:    700] loss: 0.33295 time load: 0.06757 time model: 0.32255
[epoch: 21, batch:    800] loss: 0.27900 time load: 0.06498 time model: 0.32051
[epoch: 21, batch:    900] loss: 0.40599 time load: 0.07165 time model: 0.32105
[epoch: 21, batch:   1000] loss: 0.29647 time load: 0.06774 time model: 0.32564
[epoch: 21, batch:   1100] loss: 0.32892 time load: 0.06691 time model: 0.32209
[epoch: 21, batch:   1200] loss: 0.33884 time load: 0.06614 time model: 0.32539
[epoch: 21, batch:   1300] loss: 0.35754 time load: 0.06797 time model: 0.32467
[epoch: 21, batch:   1400] loss: 0.33729 time load: 0.06350 time model: 0.32011
[epoch: 21, batch:   1500] loss: 0.37078 time load: 0.06698 time model: 0.32299
[epoch: 21, batch:   1600] loss: 0.38122 time load: 0.06367 time model: 0.32424
[epoch: 21, batch:   1700] loss: 0.31339 time load: 0.06558 time model: 0.31734
[epoch: 21, batch:   1800] loss: 0.34469 time load: 0.06658 time model: 0.32258
[epoch: 21, batch:   1900] loss: 0.29511 time load: 0.06938 time model: 0.32147
[epoch: 21, batch:   2000] loss: 0.31077 time load: 0.06683 time model: 0.31694
[epoch: 21, batch:   2100] loss: 0.34956 time load: 0.07142 time model: 0.32499
[epoch: 21, batch:   2200] loss: 0.38707 time load: 0.06132 time model: 0.32707
[epoch: 21, batch:   2300] loss: 0.35367 time load: 0.06521 time model: 0.31271
[epoch: 21, batch:   2400] loss: 0.43690 time load: 0.06144 time model: 0.31535
[epoch: 21, batch:   2500] loss: 0.34929 time load: 0.06602 time model: 0.31741
[epoch: 21, batch:   2600] loss: 0.44638 time load: 0.06825 time model: 0.31839
[epoch: 21, batch:   2700] loss: 0.31109 time load: 0.06632 time model: 0.31644
[epoch: 21, batch:   2800] loss: 0.25412 time load: 0.06416 time model: 0.31945
[epoch: 21, batch:   2900] loss: 0.36570 time load: 0.06708 time model: 0.31774
[epoch: 21, batch:   3000] loss: 0.36614 time load: 0.06993 time model: 0.31365
[epoch: 21, batch:   3100] loss: 0.34440 time load: 0.06394 time model: 0.31336
[epoch: 21, batch:   3200] loss: 0.38630 time load: 0.06317 time model: 0.31584
[epoch: 21, batch:   3300] loss: 0.40286 time load: 0.06933 time model: 0.32517
[epoch: 21, batch:   3400] loss: 0.40069 time load: 0.06558 time model: 0.31024
[epoch: 21, batch:   3500] loss: 0.38902 time load: 0.07163 time model: 0.31120
[epoch: 21, batch:   3600] loss: 0.35553 time load: 0.06792 time model: 0.31186
[epoch: 21, batch:   3700] loss: 0.36528 time load: 0.06719 time model: 0.31703
[epoch: 21, batch:   3800] loss: 0.47164 time load: 0.06650 time model: 0.30905
[epoch: 21, batch:   3900] loss: 0.37515 time load: 0.06782 time model: 0.31694
[epoch: 21, batch:   4000] loss: 0.38275 time load: 0.06586 time model: 0.31437
[epoch: 21, batch:   4100] loss: 0.33139 time load: 0.06479 time model: 0.32071
[epoch: 21, batch:   4200] loss: 0.43558 time load: 0.06284 time model: 0.32404
[epoch: 21, batch:   4300] loss: 0.36847 time load: 0.07232 time model: 0.31527
[epoch: 21, batch:   4400] loss: 0.40346 time load: 0.06614 time model: 0.31722
[epoch: 21, batch:   4500] loss: 0.42159 time load: 0.06862 time model: 0.31833
[epoch: 21, batch:   4600] loss: 0.33647 time load: 0.06673 time model: 0.31758
[epoch: 21, batch:   4700] loss: 0.38017 time load: 0.06493 time model: 0.31720
[epoch: 21, batch:   4800] loss: 0.36151 time load: 0.06676 time model: 0.31362
[epoch: 21, batch:   4900] loss: 0.31265 time load: 0.06871 time model: 0.31291
[epoch: 21, batch:   5000] loss: 0.29624 time load: 0.07298 time model: 0.31709
Epoch: 21/100 Loss: 0.3567776862807161 Train MSESteer: 1431.372 Train MSESpeed: 5.574 MSESteer: 974.129 MSESpeed: 7.302
[epoch: 22, batch:    100] loss: 0.28954 time load: 0.06176 time model: 0.32246
[epoch: 22, batch:    200] loss: 0.39420 time load: 0.06454 time model: 0.32896
[epoch: 22, batch:    300] loss: 0.37833 time load: 0.05259 time model: 0.31237
[epoch: 22, batch:    400] loss: 0.27148 time load: 0.06569 time model: 0.31468
[epoch: 22, batch:    500] loss: 0.38164 time load: 0.05125 time model: 0.31596
[epoch: 22, batch:    600] loss: 0.35634 time load: 0.06687 time model: 0.31720
[epoch: 22, batch:    700] loss: 0.30730 time load: 0.05181 time model: 0.31822
[epoch: 22, batch:    800] loss: 0.31905 time load: 0.06456 time model: 0.31497
[epoch: 22, batch:    900] loss: 0.32996 time load: 0.05310 time model: 0.31746
[epoch: 22, batch:   1000] loss: 0.40056 time load: 0.06802 time model: 0.32269
[epoch: 22, batch:   1100] loss: 0.31844 time load: 0.05558 time model: 0.32577
[epoch: 22, batch:   1200] loss: 0.32871 time load: 0.07728 time model: 0.31805
[epoch: 22, batch:   1300] loss: 0.31248 time load: 0.05469 time model: 0.32125
[epoch: 22, batch:   1400] loss: 0.28297 time load: 0.06481 time model: 0.32410
[epoch: 22, batch:   1500] loss: 0.41234 time load: 0.05535 time model: 0.31974
[epoch: 22, batch:   1600] loss: 0.32362 time load: 0.06508 time model: 0.32756
[epoch: 22, batch:   1700] loss: 0.36003 time load: 0.05241 time model: 0.31902
[epoch: 22, batch:   1800] loss: 0.38776 time load: 0.06378 time model: 0.32682
[epoch: 22, batch:   1900] loss: 0.28707 time load: 0.05387 time model: 0.32083
[epoch: 22, batch:   2000] loss: 0.30815 time load: 0.06507 time model: 0.31362
[epoch: 22, batch:   2100] loss: 0.26445 time load: 0.05572 time model: 0.31889
[epoch: 22, batch:   2200] loss: 0.30804 time load: 0.06788 time model: 0.32376
[epoch: 22, batch:   2300] loss: 0.42515 time load: 0.05474 time model: 0.32427
[epoch: 22, batch:   2400] loss: 0.34660 time load: 0.06276 time model: 0.32032
[epoch: 22, batch:   2500] loss: 0.43496 time load: 0.05501 time model: 0.32451
[epoch: 22, batch:   2600] loss: 0.37374 time load: 0.06605 time model: 0.33089
[epoch: 22, batch:   2700] loss: 0.29334 time load: 0.05523 time model: 0.31615
[epoch: 22, batch:   2800] loss: 0.38374 time load: 0.06475 time model: 0.31884
[epoch: 22, batch:   2900] loss: 0.28087 time load: 0.05425 time model: 0.32012
[epoch: 22, batch:   3000] loss: 0.31375 time load: 0.06481 time model: 0.32998
[epoch: 22, batch:   3100] loss: 0.36121 time load: 0.05540 time model: 0.31981
[epoch: 22, batch:   3200] loss: 0.33089 time load: 0.06201 time model: 0.31494
[epoch: 22, batch:   3300] loss: 0.34430 time load: 0.05371 time model: 0.31077
[epoch: 22, batch:   3400] loss: 0.31735 time load: 0.06602 time model: 0.31006
[epoch: 22, batch:   3500] loss: 0.29331 time load: 0.05333 time model: 0.31605
[epoch: 22, batch:   3600] loss: 0.38032 time load: 0.06134 time model: 0.31635
[epoch: 22, batch:   3700] loss: 0.30987 time load: 0.05165 time model: 0.31306
[epoch: 22, batch:   3800] loss: 0.36830 time load: 0.06152 time model: 0.31294
[epoch: 22, batch:   3900] loss: 0.33931 time load: 0.05494 time model: 0.31911
[epoch: 22, batch:   4000] loss: 0.33076 time load: 0.06726 time model: 0.32292
[epoch: 22, batch:   4100] loss: 0.34036 time load: 0.05477 time model: 0.32023
[epoch: 22, batch:   4200] loss: 0.32011 time load: 0.06584 time model: 0.31708
[epoch: 22, batch:   4300] loss: 0.37183 time load: 0.05299 time model: 0.31351
[epoch: 22, batch:   4400] loss: 0.27570 time load: 0.07071 time model: 0.31045
[epoch: 22, batch:   4500] loss: 0.30987 time load: 0.05661 time model: 0.31684
[epoch: 22, batch:   4600] loss: 0.31362 time load: 0.07053 time model: 0.31692
[epoch: 22, batch:   4700] loss: 0.25682 time load: 0.05489 time model: 0.32197
[epoch: 22, batch:   4800] loss: 0.44469 time load: 0.06122 time model: 0.31816
[epoch: 22, batch:   4900] loss: 0.34753 time load: 0.05584 time model: 0.33118
[epoch: 22, batch:   5000] loss: 0.30890 time load: 0.06829 time model: 0.32475
Epoch: 22/100 Loss: 0.3370918912957375 Train MSESteer: 1341.324 Train MSESpeed: 5.379 MSESteer: 1593.619 MSESpeed: 7.136
[epoch: 23, batch:    100] loss: 0.33085 time load: 0.05671 time model: 0.32247
[epoch: 23, batch:    200] loss: 0.30674 time load: 0.06503 time model: 0.32045
[epoch: 23, batch:    300] loss: 0.34189 time load: 0.05163 time model: 0.31101
[epoch: 23, batch:    400] loss: 0.27873 time load: 0.06357 time model: 0.31632
[epoch: 23, batch:    500] loss: 0.35200 time load: 0.05647 time model: 0.32370
[epoch: 23, batch:    600] loss: 0.26373 time load: 0.06561 time model: 0.32298
[epoch: 23, batch:    700] loss: 0.37781 time load: 0.05430 time model: 0.32450
[epoch: 23, batch:    800] loss: 0.41571 time load: 0.06411 time model: 0.31916
[epoch: 23, batch:    900] loss: 0.31528 time load: 0.05310 time model: 0.32397
[epoch: 23, batch:   1000] loss: 0.27146 time load: 0.06629 time model: 0.31503
[epoch: 23, batch:   1100] loss: 0.30592 time load: 0.05556 time model: 0.31986
[epoch: 23, batch:   1200] loss: 0.27479 time load: 0.06757 time model: 0.32295
[epoch: 23, batch:   1300] loss: 0.33764 time load: 0.05524 time model: 0.31876
[epoch: 23, batch:   1400] loss: 0.30974 time load: 0.07075 time model: 0.32127
[epoch: 23, batch:   1500] loss: 0.37498 time load: 0.05525 time model: 0.31544
[epoch: 23, batch:   1600] loss: 0.34345 time load: 0.06566 time model: 0.32383
[epoch: 23, batch:   1700] loss: 0.36861 time load: 0.05585 time model: 0.31644
[epoch: 23, batch:   1800] loss: 0.27149 time load: 0.06634 time model: 0.32283
[epoch: 23, batch:   1900] loss: 0.30462 time load: 0.05492 time model: 0.31517
[epoch: 23, batch:   2000] loss: 0.33286 time load: 0.06533 time model: 0.31805
[epoch: 23, batch:   2100] loss: 0.30720 time load: 0.05566 time model: 0.31634
[epoch: 23, batch:   2200] loss: 0.31152 time load: 0.06469 time model: 0.32823
[epoch: 23, batch:   2300] loss: 0.27835 time load: 0.05486 time model: 0.31673
[epoch: 23, batch:   2400] loss: 0.29680 time load: 0.07032 time model: 0.31924
[epoch: 23, batch:   2500] loss: 0.31648 time load: 0.05456 time model: 0.31902
[epoch: 23, batch:   2600] loss: 0.39945 time load: 0.06866 time model: 0.32117
[epoch: 23, batch:   2700] loss: 0.32567 time load: 0.05390 time model: 0.31609
[epoch: 23, batch:   2800] loss: 0.37649 time load: 0.06313 time model: 0.31603
[epoch: 23, batch:   2900] loss: 0.38321 time load: 0.05426 time model: 0.31924
[epoch: 23, batch:   3000] loss: 0.26376 time load: 0.06458 time model: 0.31487
[epoch: 23, batch:   3100] loss: 0.28353 time load: 0.05564 time model: 0.32734
[epoch: 23, batch:   3200] loss: 0.35503 time load: 0.06399 time model: 0.31777
[epoch: 23, batch:   3300] loss: 0.31215 time load: 0.05414 time model: 0.32558
[epoch: 23, batch:   3400] loss: 0.35147 time load: 0.06921 time model: 0.32356
[epoch: 23, batch:   3500] loss: 0.32350 time load: 0.05520 time model: 0.32161
[epoch: 23, batch:   3600] loss: 0.33024 time load: 0.06794 time model: 0.31853
[epoch: 23, batch:   3700] loss: 0.40396 time load: 0.05486 time model: 0.31898
[epoch: 23, batch:   3800] loss: 0.33389 time load: 0.07259 time model: 0.31742
[epoch: 23, batch:   3900] loss: 0.35688 time load: 0.05578 time model: 0.31941
[epoch: 23, batch:   4000] loss: 0.31223 time load: 0.06944 time model: 0.31533
[epoch: 23, batch:   4100] loss: 0.32951 time load: 0.05427 time model: 0.31704
[epoch: 23, batch:   4200] loss: 0.36934 time load: 0.06714 time model: 0.32180
[epoch: 23, batch:   4300] loss: 0.29803 time load: 0.05560 time model: 0.32030
[epoch: 23, batch:   4400] loss: 0.36390 time load: 0.06877 time model: 0.31763
[epoch: 23, batch:   4500] loss: 0.34926 time load: 0.05418 time model: 0.31906
[epoch: 23, batch:   4600] loss: 0.27784 time load: 0.06575 time model: 0.31899
[epoch: 23, batch:   4700] loss: 0.35559 time load: 0.05487 time model: 0.32004
[epoch: 23, batch:   4800] loss: 0.38884 time load: 0.06657 time model: 0.31360
[epoch: 23, batch:   4900] loss: 0.31412 time load: 0.05472 time model: 0.32039
[epoch: 23, batch:   5000] loss: 0.29538 time load: 0.06340 time model: 0.32113
Epoch: 23/100 Loss: 0.32940072055406733 Train MSESteer: 1311.832 Train MSESpeed: 5.264 MSESteer: 749.259 MSESpeed: 7.437
[epoch: 24, batch:    100] loss: 0.30879 time load: 0.06748 time model: 0.31618
[epoch: 24, batch:    200] loss: 0.25300 time load: 0.06824 time model: 0.32218
[epoch: 24, batch:    300] loss: 0.35354 time load: 0.06662 time model: 0.32233
[epoch: 24, batch:    400] loss: 0.30858 time load: 0.06584 time model: 0.32075
[epoch: 24, batch:    500] loss: 0.35911 time load: 0.06705 time model: 0.33196
[epoch: 24, batch:    600] loss: 0.31081 time load: 0.07546 time model: 0.32446
[epoch: 24, batch:    700] loss: 0.26224 time load: 0.06977 time model: 0.32030
[epoch: 24, batch:    800] loss: 0.43888 time load: 0.06639 time model: 0.31698
[epoch: 24, batch:    900] loss: 0.30381 time load: 0.07087 time model: 0.32059
[epoch: 24, batch:   1000] loss: 0.25307 time load: 0.07667 time model: 0.32218
[epoch: 24, batch:   1100] loss: 0.29801 time load: 0.06633 time model: 0.31402
[epoch: 24, batch:   1200] loss: 0.28241 time load: 0.06480 time model: 0.31979
[epoch: 24, batch:   1300] loss: 0.25294 time load: 0.06586 time model: 0.31968
[epoch: 24, batch:   1400] loss: 0.34759 time load: 0.06526 time model: 0.32002
[epoch: 24, batch:   1500] loss: 0.33975 time load: 0.07362 time model: 0.31906
[epoch: 24, batch:   1600] loss: 0.35945 time load: 0.06658 time model: 0.31654
[epoch: 24, batch:   1700] loss: 0.25092 time load: 0.06548 time model: 0.32274
[epoch: 24, batch:   1800] loss: 0.43114 time load: 0.14391 time model: 0.33367
[epoch: 24, batch:   1900] loss: 0.38814 time load: 0.08549 time model: 0.31942
[epoch: 24, batch:   2000] loss: 0.32463 time load: 0.06530 time model: 0.31278
[epoch: 24, batch:   2100] loss: 0.37857 time load: 0.06561 time model: 0.31417
[epoch: 24, batch:   2200] loss: 0.33389 time load: 0.06894 time model: 0.31114
[epoch: 24, batch:   2300] loss: 0.34454 time load: 0.06441 time model: 0.31456
[epoch: 24, batch:   2400] loss: 0.40275 time load: 0.06606 time model: 0.30998
[epoch: 24, batch:   2500] loss: 0.40078 time load: 0.06750 time model: 0.31542
[epoch: 24, batch:   2600] loss: 0.32645 time load: 0.06712 time model: 0.31070
[epoch: 24, batch:   2700] loss: 0.33298 time load: 0.06609 time model: 0.31549
[epoch: 24, batch:   2800] loss: 0.26706 time load: 0.06517 time model: 0.31945
[epoch: 24, batch:   2900] loss: 0.29839 time load: 0.06466 time model: 0.32976
[epoch: 24, batch:   3000] loss: 0.41787 time load: 0.06720 time model: 0.31895
[epoch: 24, batch:   3100] loss: 0.25705 time load: 0.07378 time model: 0.32163
[epoch: 24, batch:   3200] loss: 0.29615 time load: 0.07355 time model: 0.32465
[epoch: 24, batch:   3300] loss: 0.24640 time load: 0.06895 time model: 0.31677
[epoch: 24, batch:   3400] loss: 0.32924 time load: 0.06236 time model: 0.31785
[epoch: 24, batch:   3500] loss: 0.26120 time load: 0.06615 time model: 0.31098
[epoch: 24, batch:   3600] loss: 0.28041 time load: 0.06264 time model: 0.31340
[epoch: 24, batch:   3700] loss: 0.31476 time load: 0.06230 time model: 0.31283
[epoch: 24, batch:   3800] loss: 0.26714 time load: 0.06301 time model: 0.32600
[epoch: 24, batch:   3900] loss: 0.34964 time load: 0.06386 time model: 0.31087
[epoch: 24, batch:   4000] loss: 0.41112 time load: 0.06585 time model: 0.30923
[epoch: 24, batch:   4100] loss: 0.27418 time load: 0.06708 time model: 0.31889
[epoch: 24, batch:   4200] loss: 0.34941 time load: 0.06906 time model: 0.32314
[epoch: 24, batch:   4300] loss: 0.26147 time load: 0.06638 time model: 0.31964
[epoch: 24, batch:   4400] loss: 0.35601 time load: 0.06498 time model: 0.32398
[epoch: 24, batch:   4500] loss: 0.34375 time load: 0.06604 time model: 0.31435
[epoch: 24, batch:   4600] loss: 0.25717 time load: 0.06724 time model: 0.31618
[epoch: 24, batch:   4700] loss: 0.31576 time load: 0.07540 time model: 0.32276
[epoch: 24, batch:   4800] loss: 0.38453 time load: 0.06829 time model: 0.31745
[epoch: 24, batch:   4900] loss: 0.29708 time load: 0.06932 time model: 0.32113
[epoch: 24, batch:   5000] loss: 0.35329 time load: 0.06472 time model: 0.31657
Epoch: 24/100 Loss: 0.3225400158028113 Train MSESteer: 1274.719 Train MSESpeed: 5.265 MSESteer: 869.808 MSESpeed: 7.14
[epoch: 25, batch:    100] loss: 0.32727 time load: 0.05735 time model: 0.32328
[epoch: 25, batch:    200] loss: 0.38119 time load: 0.06218 time model: 0.32018
[epoch: 25, batch:    300] loss: 0.24818 time load: 0.05618 time model: 0.32755
[epoch: 25, batch:    400] loss: 0.32717 time load: 0.06144 time model: 0.32234
[epoch: 25, batch:    500] loss: 0.23662 time load: 0.05526 time model: 0.32539
[epoch: 25, batch:    600] loss: 0.30426 time load: 0.06213 time model: 0.32401
[epoch: 25, batch:    700] loss: 0.32205 time load: 0.05460 time model: 0.32013
[epoch: 25, batch:    800] loss: 0.28590 time load: 0.06204 time model: 0.32068
[epoch: 25, batch:    900] loss: 0.35924 time load: 0.05441 time model: 0.32001
[epoch: 25, batch:   1000] loss: 0.32146 time load: 0.06515 time model: 0.31688
[epoch: 25, batch:   1100] loss: 0.27764 time load: 0.05465 time model: 0.32847
[epoch: 25, batch:   1200] loss: 0.29089 time load: 0.06033 time model: 0.32469
[epoch: 25, batch:   1300] loss: 0.33809 time load: 0.05532 time model: 0.31630
[epoch: 25, batch:   1400] loss: 0.26882 time load: 0.06413 time model: 0.31787
[epoch: 25, batch:   1500] loss: 0.35529 time load: 0.05584 time model: 0.32143
[epoch: 25, batch:   1600] loss: 0.31340 time load: 0.06367 time model: 0.32173
[epoch: 25, batch:   1700] loss: 0.21847 time load: 0.06379 time model: 0.32579
[epoch: 25, batch:   1800] loss: 0.32037 time load: 0.05511 time model: 0.32252
[epoch: 25, batch:   1900] loss: 0.28099 time load: 0.05483 time model: 0.32040
[epoch: 25, batch:   2000] loss: 0.30224 time load: 0.05263 time model: 0.32073
[epoch: 25, batch:   2100] loss: 0.33242 time load: 0.05608 time model: 0.32193
[epoch: 25, batch:   2200] loss: 0.26944 time load: 0.05437 time model: 0.30892
[epoch: 25, batch:   2300] loss: 0.36407 time load: 0.05373 time model: 0.31177
[epoch: 25, batch:   2400] loss: 0.35434 time load: 0.06393 time model: 0.32104
[epoch: 25, batch:   2500] loss: 0.38333 time load: 0.05487 time model: 0.32730
[epoch: 25, batch:   2600] loss: 0.28739 time load: 0.05215 time model: 0.31204
[epoch: 25, batch:   2700] loss: 0.31507 time load: 0.10670 time model: 0.30736
[epoch: 25, batch:   2800] loss: 0.30003 time load: 0.05193 time model: 0.31031
[epoch: 25, batch:   2900] loss: 0.26325 time load: 0.10411 time model: 0.31956
[epoch: 25, batch:   3000] loss: 0.29950 time load: 0.05508 time model: 0.31983
[epoch: 25, batch:   3100] loss: 0.36287 time load: 0.10955 time model: 0.32477
[epoch: 25, batch:   3200] loss: 0.35281 time load: 0.05523 time model: 0.32029
[epoch: 25, batch:   3300] loss: 0.32389 time load: 0.10236 time model: 0.32477
[epoch: 25, batch:   3400] loss: 0.31425 time load: 0.05202 time model: 0.31370
[epoch: 25, batch:   3500] loss: 0.31171 time load: 0.11670 time model: 0.31458
[epoch: 25, batch:   3600] loss: 0.33514 time load: 0.05589 time model: 0.32010
[epoch: 25, batch:   3700] loss: 0.28084 time load: 0.10760 time model: 0.32677
[epoch: 25, batch:   3800] loss: 0.32347 time load: 0.05465 time model: 0.31773
[epoch: 25, batch:   3900] loss: 0.42416 time load: 0.10489 time model: 0.31815
[epoch: 25, batch:   4000] loss: 0.31417 time load: 0.05459 time model: 0.32202
[epoch: 25, batch:   4100] loss: 0.28779 time load: 0.10636 time model: 0.32177
[epoch: 25, batch:   4200] loss: 0.27674 time load: 0.05677 time model: 0.31934
[epoch: 25, batch:   4300] loss: 0.28079 time load: 0.11012 time model: 0.31497
[epoch: 25, batch:   4400] loss: 0.31508 time load: 0.05338 time model: 0.31837
[epoch: 25, batch:   4500] loss: 0.30108 time load: 0.10854 time model: 0.32384
[epoch: 25, batch:   4600] loss: 0.40600 time load: 0.05495 time model: 0.32234
[epoch: 25, batch:   4700] loss: 0.30046 time load: 0.11108 time model: 0.31295
[epoch: 25, batch:   4800] loss: 0.26863 time load: 0.05371 time model: 0.32117
[epoch: 25, batch:   4900] loss: 0.35974 time load: 0.09721 time model: 0.31227
[epoch: 25, batch:   5000] loss: 0.35270 time load: 0.05361 time model: 0.32436
Epoch: 25/100 Loss: 0.314873361761584 Train MSESteer: 1238.75 Train MSESpeed: 5.2 MSESteer: 807.081 MSESpeed: 8.804
[epoch: 26, batch:    100] loss: 0.25840 time load: 0.05713 time model: 0.32015
[epoch: 26, batch:    200] loss: 0.26047 time load: 0.07451 time model: 0.31979
[epoch: 26, batch:    300] loss: 0.28564 time load: 0.05573 time model: 0.32751
[epoch: 26, batch:    400] loss: 0.27079 time load: 0.06641 time model: 0.32076
[epoch: 26, batch:    500] loss: 0.40542 time load: 0.05642 time model: 0.31392
[epoch: 26, batch:    600] loss: 0.33682 time load: 0.06714 time model: 0.32291
[epoch: 26, batch:    700] loss: 0.26204 time load: 0.05959 time model: 0.31799
[epoch: 26, batch:    800] loss: 0.25379 time load: 0.06508 time model: 0.31207
[epoch: 26, batch:    900] loss: 0.29595 time load: 0.05529 time model: 0.31671
[epoch: 26, batch:   1000] loss: 0.28499 time load: 0.06465 time model: 0.31760
[epoch: 26, batch:   1100] loss: 0.34960 time load: 0.06084 time model: 0.32557
[epoch: 26, batch:   1200] loss: 0.27449 time load: 0.06859 time model: 0.32541
[epoch: 26, batch:   1300] loss: 0.26521 time load: 0.05589 time model: 0.31340
[epoch: 26, batch:   1400] loss: 0.26593 time load: 0.05529 time model: 0.31282
[epoch: 26, batch:   1500] loss: 0.32480 time load: 0.05888 time model: 0.31446
[epoch: 26, batch:   1600] loss: 0.27252 time load: 0.05698 time model: 0.32171
[epoch: 26, batch:   1700] loss: 0.28339 time load: 0.05692 time model: 0.31857
[epoch: 26, batch:   1800] loss: 0.31296 time load: 0.05658 time model: 0.31700
[epoch: 26, batch:   1900] loss: 0.27360 time load: 0.05715 time model: 0.32367
[epoch: 26, batch:   2000] loss: 0.29451 time load: 0.06899 time model: 0.31129
[epoch: 26, batch:   2100] loss: 0.29647 time load: 0.05625 time model: 0.31305
[epoch: 26, batch:   2200] loss: 0.29799 time load: 0.05809 time model: 0.32895
[epoch: 26, batch:   2300] loss: 0.33759 time load: 0.05769 time model: 0.31331
[epoch: 26, batch:   2400] loss: 0.35262 time load: 0.06009 time model: 0.32189
[epoch: 26, batch:   2500] loss: 0.33995 time load: 0.06198 time model: 0.32198
[epoch: 26, batch:   2600] loss: 0.28666 time load: 0.05870 time model: 0.32022
[epoch: 26, batch:   2700] loss: 0.30010 time load: 0.06954 time model: 0.32304
[epoch: 26, batch:   2800] loss: 0.31332 time load: 0.05722 time model: 0.32249
[epoch: 26, batch:   2900] loss: 0.29650 time load: 0.05871 time model: 0.32209
[epoch: 26, batch:   3000] loss: 0.31094 time load: 0.05793 time model: 0.32890
[epoch: 26, batch:   3100] loss: 0.35914 time load: 0.05852 time model: 0.31948
[epoch: 26, batch:   3200] loss: 0.34092 time load: 0.05743 time model: 0.32083
[epoch: 26, batch:   3300] loss: 0.45143 time load: 0.05799 time model: 0.32308
[epoch: 26, batch:   3400] loss: 0.32455 time load: 0.05936 time model: 0.31642
[epoch: 26, batch:   3500] loss: 0.31088 time load: 0.05723 time model: 0.31907
[epoch: 26, batch:   3600] loss: 0.29154 time load: 0.06533 time model: 0.32178
[epoch: 26, batch:   3700] loss: 0.31570 time load: 0.05872 time model: 0.32928
[epoch: 26, batch:   3800] loss: 0.33017 time load: 0.05794 time model: 0.31872
[epoch: 26, batch:   3900] loss: 0.35531 time load: 0.10793 time model: 0.31637
[epoch: 26, batch:   4000] loss: 0.30477 time load: 0.05455 time model: 0.31210
[epoch: 26, batch:   4100] loss: 0.28248 time load: 0.10093 time model: 0.30966
[epoch: 26, batch:   4200] loss: 0.35427 time load: 0.05778 time model: 0.31797
[epoch: 26, batch:   4300] loss: 0.29852 time load: 0.11013 time model: 0.31704
[epoch: 26, batch:   4400] loss: 0.29828 time load: 0.06035 time model: 0.32445
[epoch: 26, batch:   4500] loss: 0.28721 time load: 0.11093 time model: 0.31596
[epoch: 26, batch:   4600] loss: 0.29313 time load: 0.05646 time model: 0.31856
[epoch: 26, batch:   4700] loss: 0.36323 time load: 0.10980 time model: 0.32436
[epoch: 26, batch:   4800] loss: 0.30879 time load: 0.05834 time model: 0.31642
[epoch: 26, batch:   4900] loss: 0.30579 time load: 0.11601 time model: 0.31843
[epoch: 26, batch:   5000] loss: 0.33007 time load: 0.05492 time model: 0.31943
Epoch: 26/100 Loss: 0.30932452713225234 Train MSESteer: 1209.61 Train MSESpeed: 5.194 MSESteer: 1914.079 MSESpeed: 8.291
[epoch: 27, batch:    100] loss: 0.30932 time load: 0.05856 time model: 0.31466
[epoch: 27, batch:    200] loss: 0.26617 time load: 0.06333 time model: 0.32028
[epoch: 27, batch:    300] loss: 0.26609 time load: 0.05483 time model: 0.31474
[epoch: 27, batch:    400] loss: 0.37391 time load: 0.07465 time model: 0.31568
[epoch: 27, batch:    500] loss: 0.23814 time load: 0.05635 time model: 0.32188
[epoch: 27, batch:    600] loss: 0.30522 time load: 0.06705 time model: 0.32142
[epoch: 27, batch:    700] loss: 0.26233 time load: 0.05761 time model: 0.32018
[epoch: 27, batch:    800] loss: 0.28168 time load: 0.06808 time model: 0.31501
[epoch: 27, batch:    900] loss: 0.27438 time load: 0.05574 time model: 0.31013
[epoch: 27, batch:   1000] loss: 0.25707 time load: 0.06704 time model: 0.32597
[epoch: 27, batch:   1100] loss: 0.35946 time load: 0.06191 time model: 0.32136
[epoch: 27, batch:   1200] loss: 0.27721 time load: 0.06582 time model: 0.32165
[epoch: 27, batch:   1300] loss: 0.29961 time load: 0.05833 time model: 0.32274
[epoch: 27, batch:   1400] loss: 0.34606 time load: 0.06675 time model: 0.32403
[epoch: 27, batch:   1500] loss: 0.32845 time load: 0.05715 time model: 0.31630
[epoch: 27, batch:   1600] loss: 0.36812 time load: 0.06298 time model: 0.32037
[epoch: 27, batch:   1700] loss: 0.35240 time load: 0.05647 time model: 0.31641
[epoch: 27, batch:   1800] loss: 0.26776 time load: 0.06634 time model: 0.31649
[epoch: 27, batch:   1900] loss: 0.33247 time load: 0.05597 time model: 0.32033
[epoch: 27, batch:   2000] loss: 0.29636 time load: 0.06496 time model: 0.32178
[epoch: 27, batch:   2100] loss: 0.26486 time load: 0.05532 time model: 0.31760
[epoch: 27, batch:   2200] loss: 0.24483 time load: 0.06379 time model: 0.31601
[epoch: 27, batch:   2300] loss: 0.40707 time load: 0.05622 time model: 0.32170
[epoch: 27, batch:   2400] loss: 0.36758 time load: 0.07137 time model: 0.32055
[epoch: 27, batch:   2500] loss: 0.43861 time load: 0.06407 time model: 0.31468
[epoch: 27, batch:   2600] loss: 0.32074 time load: 0.06565 time model: 0.32150
[epoch: 27, batch:   2700] loss: 0.40694 time load: 0.05727 time model: 0.32827
[epoch: 27, batch:   2800] loss: 0.31138 time load: 0.06507 time model: 0.32237
[epoch: 27, batch:   2900] loss: 0.32869 time load: 0.05599 time model: 0.31694
[epoch: 27, batch:   3000] loss: 0.27870 time load: 0.06256 time model: 0.31500
[epoch: 27, batch:   3100] loss: 0.30782 time load: 0.05525 time model: 0.31997
[epoch: 27, batch:   3200] loss: 0.29758 time load: 0.06522 time model: 0.31996
[epoch: 27, batch:   3300] loss: 0.27463 time load: 0.05495 time model: 0.31830
[epoch: 27, batch:   3400] loss: 0.25119 time load: 0.06824 time model: 0.31761
[epoch: 27, batch:   3500] loss: 0.31084 time load: 0.05435 time model: 0.31565
[epoch: 27, batch:   3600] loss: 0.35123 time load: 0.05707 time model: 0.31396
[epoch: 27, batch:   3700] loss: 0.33217 time load: 0.05308 time model: 0.31179
[epoch: 27, batch:   3800] loss: 0.42071 time load: 0.05551 time model: 0.31377
[epoch: 27, batch:   3900] loss: 0.43578 time load: 0.05610 time model: 0.31464
[epoch: 27, batch:   4000] loss: 0.31248 time load: 0.05632 time model: 0.31608
[epoch: 27, batch:   4100] loss: 0.28270 time load: 0.05716 time model: 0.31776
[epoch: 27, batch:   4200] loss: 0.24450 time load: 0.05713 time model: 0.31940
[epoch: 27, batch:   4300] loss: 0.28470 time load: 0.05694 time model: 0.31780
[epoch: 27, batch:   4400] loss: 0.30818 time load: 0.05727 time model: 0.31689
[epoch: 27, batch:   4500] loss: 0.28372 time load: 0.05829 time model: 0.31821
[epoch: 27, batch:   4600] loss: 0.33345 time load: 0.05806 time model: 0.31492
[epoch: 27, batch:   4700] loss: 0.26447 time load: 0.05877 time model: 0.32669
[epoch: 27, batch:   4800] loss: 0.27834 time load: 0.05623 time model: 0.31516
[epoch: 27, batch:   4900] loss: 0.35955 time load: 0.05592 time model: 0.32202
[epoch: 27, batch:   5000] loss: 0.31877 time load: 0.05583 time model: 0.31494
